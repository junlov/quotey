{"id": "quotey-001", "title": "EPIC-V2-MCP: MCP Server for AI Agents", "status": "in_progress", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:00:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:25:00Z", "description": "## Overview\nMake Quotey controllable by AI coding agents via Model Context Protocol (MCP). AI agents can programmatically query pricing, create quotes, check approvals, and trigger document generation.\n\n## Why This Matters\nEvery other CPQ tool requires human interaction only. AI agents become internal users, enabling AI-powered quoting workflows. This is a critical differentiator - no competitor offers this. Opens new use cases: automated deal scoring, AI quote optimization, programmatic quote generation.\n\n## Background\nMCP is an open protocol enabling AI agents to connect to tools and services. By exposing Quotey via MCP, we enable Claude Code and other AI agents to create quotes programmatically, automated workflows from external systems, and integration with AI-powered CRM systems.\n\n## Technical Considerations\n- MCP server implementation in Rust (use existing MCP SDK or build custom)\n- Define tool schema for each Quotey capability following MCP conventions\n- Support API key and OAuth authentication\n- Handle rate limiting and error responses properly\n- Ensure idempotency for agent retries\n- Full audit trail for ALL agent actions (critical for enterprise)\n\n## Goals\n1. Agents can query product catalog programmatically\n2. Agents can create and price quotes\n3. Agents can check approval status and trigger approval flows\n4. Agents can trigger PDF generation\n5. Full audit trail exists for all agent actions\n\n## Dependencies\nNone - foundational capability, can start immediately\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #1]", "labels": ["v2", "mcp", "ai-agents", "epic", "foundational"], "assigned_to": "Kimi"}
{"id": "quotey-002", "title": "EPIC-V2-SUGGEST: Smart Product Suggestions Engine", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:01:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:01:00Z", "description": "## Overview\nAfter a rep selects a customer, the system automatically recommends products based on what similar customers bought, the customer's industry, their current contract, seasonal trends, and cross-sell/upsell opportunities. One-click to add.\n\n## Why This Matters\nReps spend too much time hunting through catalogs. This makes the system feel magical - it knows what the customer likely needs. Increases average deal size through intelligent cross-sell/upsell suggestions. Reduces training burden - reps don't need to memorize the entire catalog.\n\n## Background\nThis is a recommendation engine built on top of historical quote data. The system learns from past successful deals and applies that pattern to new opportunities. It's not about replacing human judgment - it's about surfacing relevant options quickly.\n\n## Technical Considerations\n- Similarity scoring algorithm based on: customer segment, industry, deal size, product categories\n- Collaborative filtering: \"customers like this also bought...\"\n- Content-based: product relationships, bundles, add-ons\n- Time-decay for seasonality (Q4 deals different from Q1)\n- Configurable suggestion rules (e.g., always suggest onboarding for Enterprise)\n- Privacy-aware: suggestions based on anonymized aggregate data, not individual customer data\n\n## User Experience\nWhen rep selects a customer, show 3-5 product suggestions with brief reasoning:\n- \"Based on Acme's industry (FinTech), we typically include SOC2 compliance add-on\"\n- \"Enterprise customers like Acme often add premium support in year 1\"\n- \"Similar mid-market deals included SSO (3 of last 5)\"\n\n## Goals\n1. Display 3-5 relevant product suggestions per customer\n2. Show reasoning for each suggestion\n3. One-click add to quote\n4. Learn from accepted/rejected suggestions (feedback loop)\n5. Configurable suggestion rules by segment\n\n## Dependencies\n- EPIC-V2-MCP (can be independent but suggestions enhance MCP tools)\n- Historical quote data (existing in v1)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #2]", "labels": ["v2", "recommendations", "ux", "epic", "productivity"]}
{"id": "quotey-003", "title": "EPIC-V2-PORTAL: Web Quote Portal", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:02:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:02:00Z", "description": "## Overview\nA lightweight web UI alongside Slack - not a full dashboard, just a shareable link customers can view interactively, approve electronically (e-signature capture), and download PDFs from. Replaces clumsy PDF attachments with a modern experience.\n\n## Why This Matters\nPDFs are static and clumsy. Customers can't easily ask questions or approve. A web portal allows interactive quote exploration, shows pricing breakdowns, lets customers compare options, and captures explicit approval with timestamp. Complements Slack without replacing it - the quote lives in Slack, but the customer experience is web-native.\n\n## Background\nSales reps currently send PDFs via email which get lost in inboxes. Customers can't easily compare options or ask clarifications. This creates friction in the close process. A web portal solves this while maintaining the Slack-first workflow for reps.\n\n## Technical Considerations\n- Minimal web server (Axum in Rust, or embedded static files)\n- Shareable links with expiration (configurable, default 30 days)\n- No authentication required for customers (link-based access)\n- Optional: password protection for sensitive deals\n- Electronic signature capture (simple click-to-approve + timestamp)\n- Customer can add comments/questions on specific line items\n- Mobile-responsive design\n- All data served from local SQLite (no external dependencies)\n\n## User Experience\nRep clicks \"Share Link\" in Slack, system generates unique URL. Customer receives link, can:\n- View full quote with pricing breakdown\n- Compare different configuration options\n- Ask questions (goes back to rep via Slack)\n- Approve electronically (triggers workflow in Quotey)\n- Download PDF\n\n## Goals\n1. Generate secure shareable links for quotes\n2. Interactive quote viewer with pricing breakdown\n3. Customer can approve/reject with electronic signature\n4. Customer can comment on specific line items\n5. Links expire after configurable duration\n\n## Dependencies\n- PDF generation (exists in v1)\n- Slack integration (exists in v1)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #3]", "labels": ["v2", "portal", "ux", "epic", "multi-channel"]}
{"id": "quotey-004", "title": "EPIC-V2-RULES: Visual No-Code Rule Builder", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:03:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:03:00Z", "description": "## Overview\nA Slack modal or CLI tool that lets sales ops admins build pricing rules and constraints visually - dropdowns, condition builders, formula editors - without writing SQL. Exports directly to SQLite.\n\n## Why This Matters\nCurrent Quotey requires SQL knowledge to manage pricing rules and constraints. This limits who can make changes to developers only. Sales ops need to be able to adjust discount caps, add new pricing tiers, and modify constraints without waiting for engineering. Democratizes setup to the people who understand the business.\n\n## Background\nIn v1, pricing rules, constraints, and policies are stored in SQLite but require SQL to manage. This creates a bottleneck. A visual builder lets sales ops make changes quickly while ensuring data integrity.\n\n## Technical Considerations\n- Slack modal UI for rule building\n- Alternative: CLI interactive wizard\n- Condition builder: field selector \u2192 operator \u2192 value\n- Formula editor with variable picker\n- Preview what rule will look like in SQL\n- Validation: test rule against sample data before saving\n- Version control: changes tracked in audit log\n- Import/export rules as JSON (for backup/versioning)\n\n## Rule Types to Support\n1. Pricing rules (base prices, volume tiers, formulas)\n2. Discount policies (caps by segment, product, deal size)\n3. Constraint rules (requires, excludes, attribute constraints)\n4. Approval thresholds (by discount %, deal value, margin)\n\n## User Experience\nAdmin opens \"/quotey rules\" in Slack, selects rule type, fills in form:\n- Rule name: \"SMB Discount Cap\"\n- Condition: \"customer_segment = SMB AND deal_size < 10000\"\n- Action: \"max_discount = 10%\"\n- Preview shows affected quotes\n- Save creates/updates rule in SQLite\n\n## Goals\n1. Visual builder for pricing rules\n2. Visual builder for constraint rules\n3. Visual builder for discount policies\n4. Visual builder for approval thresholds\n5. Preview and test before save\n6. Audit trail of all changes\n\n## Dependencies\n- Slack integration (exists in v1)\n- SQLite schema for rules (exists in v1)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #4]", "labels": ["v2", "rules", "admin", "ux", "epic", "no-code"]}
{"id": "quotey-005", "title": "EPIC-V2-AUTOQUOTE: Auto-Quote from Email/RFP", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:04:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:04:00Z", "description": "## Overview\nDrop an email or paste an RFP text, and the system extracts requirements, maps them to products, identifies ambiguities that need clarification, and drafts a complete quote. Rep reviews and tweaks before sending.\n\n## Why This Matters\nThis is THE key differentiator. Reps spend hours manually parsing customer requests, RFPs, and emails to build quotes. This does it in seconds. The #1 blocker to CPQ adoption is data entry time - this eliminates it.\n\n## Background\nAlready planned in PROJECT.md as \"Quote Intelligence\" but needs emphasis. This feature takes unstructured input (email, RFP, Slack thread) and converts it to structured quote data using LLM extraction + product matching.\n\n## Technical Considerations\n- Email parser: extract requirements from plain text emails\n- RFP parser: more complex, multi-section document with tables\n- Slack thread parser: conversation history \u2192 requirements\n- Product matching: fuzzy name matching + attribute mapping\n- Ambiguity detection: flag items that need human clarification\n- Draft builder: create quote in \"draft\" state for review\n- Confidence scoring: show how confident the system is\n\n## User Experience\nRep pastes RFP text into Slack:\n```\n/quote parse-rfp\n[PASTE RFP CONTENT]\n```\n\nSystem responds:\n```\n\ud83d\udccb Draft Quote Created\n\nExtracted Requirements:\n- 150 user seats \u2713\n- SSO integration \u2192 matched to \"SSO Add-on\" (95% confidence)\n- 24/7 support \u2192 matched to \"Premium Support\" (98% confidence)\n- Annual billing \u2192 understood\n- Need: clarification on \"enterprise tier\" - did they mean Pro or Enterprise plan?\n\n[ View Draft ] [ Edit ] [ Confirm ]\n```\n\n## Goals\n1. Parse email \u2192 requirements\n2. Parse RFP \u2192 requirements (with table support)\n3. Match requirements to products automatically\n4. Flag ambiguities for human clarification\n5. Draft quote creation for review\n6. Confidence scoring on matches\n\n## Dependencies\n- LLM integration (exists in v1)\n- Product catalog (exists in v1)\n- Quote creation flow (exists in v1)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #5]", "labels": ["v2", "intelligence", "rfp", "automation", "epic", "differentiation"]}
{"id": "quotey-006", "title": "EPIC-V2-ANOMALY: Pricing Anomaly Detection", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:05:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:05:00Z", "description": "## Overview\nBefore a quote finalizes, the system automatically flags unusual patterns: discount way above customer's historical average, margin below floor for the product category, configuration that's valid but unusual, price that differs significantly from similar deals.\n\n## Why This Matters\nCatches mistakes before they become problems. Sales reps will trust the system more because it catches errors. Reduces pricing errors that cost money. Provides early warning on unusual deals that might need extra scrutiny.\n\n## Background\nTraditional CPQ validates against rules but doesn't detect patterns. This adds ML-style anomaly detection (but deterministic, not actual ML) to surface unusual quotes for review.\n\n## Technical Considerations\n- Historical baseline: calculate average discount/margin per customer segment\n- Standard deviation alerts: flag quotes > 2 std dev from norm\n- Product combo detection: unusual product combinations\n- Price comparison: compare to similar deals (same products, segment, region)\n- Configurable thresholds: different segments can have different sensitivity\n- Alert UI: show flagged items with explanation\n- Override capability: rep can override with justification\n\n## Anomaly Types\n1. **Discount anomaly**: discount significantly higher than customer's history\n2. **Margin anomaly**: margin below floor for product category\n3. **Config anomaly**: valid but unusual configuration (e.g., huge quantity)\n4. **Price anomaly**: total significantly different from similar deals\n5. **Velocity anomaly**: quote created very quickly (might be automated gaming)\n\n## User Experience\nWhen rep tries to finalize quote:\n```\n\u26a0\ufe0f Quote flagged for review\n\n- Discount (18%) is 2.3x customer's average (7.8%)\n- Margin (52%) is below SaaS floor (60%)\n- First time ordering \"Onboarding\" add-on\n\n[ Override with Justification ] [ Adjust Quote ] [ View Similar Deals ]\n```\n\n## Goals\n1. Detect discount anomalies\n2. Detect margin anomalies\n3. Detect configuration anomalies\n4. Detect price anomalies\n5. Show reasoning for flags\n6. Allow override with justification\n7. Audit trail of overrides\n\n## Dependencies\n- Historical quote data (exists in v1)\n- Pricing engine (exists in v1)\n- Policy engine (exists in v1)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #6]", "labels": ["v2", "safety", "quality", "anomaly-detection", "epic"]}
{"id": "quotey-007", "title": "EPIC-V2-PDF: Branded PDF Templates + White-Label", "status": "open", "priority": 2, "issue_type": "epic", "created_at": "2026-02-26T11:06:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:06:00Z", "description": "## Overview\nShip with 5 professional quote templates (executive summary, detailed line items, product comparison, renewal, compact) with customizable branding. Users upload logo, customize colors, set as defaults. White-label option for partners/resellers.\n\n## Why This Matters\nThe quote IS the product. It represents your company to the customer. Professional, branded quotes build trust. Different templates for different situations (executive summary for quick decisions, detailed for procurement).\n\n## Background\nv1 has basic PDF generation. This adds multiple templates and customization.\n\n## Technical Considerations\n- Template engine: Tera/Handlebars (already in use)\n- 5 templates:\n  1. Executive Summary: 1-page, high-level, for quick decisions\n  2. Detailed: full line items, all pricing breakdowns\n  3. Comparison: side-by-side product/price options\n  4. Renewal: shows current\u2192proposed changes\n  5. Compact: minimal, for emails\n- Customization: logo upload, primary/secondary colors, company info\n- White-label: custom sender name/logo, remove Quotey branding\n- Template selection: default per quote type, overridable\n- PDF optimization: proper font embedding, vector graphics\n\n## User Experience\nAdmin goes to \"/quotey templates\" in Slack:\n- View current templates\n- Upload logo (drag & drop)\n- Set primary color (color picker)\n- Preview each template\n- Set defaults by quote type\n\nRep generating PDF:\n```\n[ Generate PDF (Executive Summary) ]\n[ Generate PDF (Detailed) ]\n[ Generate PDF (Comparison) ]\n[ Customize Template ]\n```\n\n## Goals\n1. 5 professional templates\n2. Logo upload and customization\n3. Color scheme customization\n4. Company info customization\n5. White-label option\n6. Default template per quote type\n7. PDF quality: proper fonts, vectors\n\n## Dependencies\n- PDF generation (exists in v1)\n- Template engine (exists in v1)\n- File upload (Slack - exists in v1)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #7]", "labels": ["v2", "pdf", "templates", "branding", "epic"]}
{"id": "quotey-008", "title": "EPIC-V2-MOBILE: Mobile Approval App (PWA)", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:07:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:07:00Z", "description": "## Overview\nA minimal PWA (Progressive Web App) where managers see pending approval requests, view deal context (customer history, margin impact, competitive situation), and approve/reject with one tap. Works on iOS and Android.\n\n## Why This Matters\nDeals stall because managers aren't at their desks. They're in meetings, traveling, or working remotely. Mobile approvals unblock deals faster. The #1 cause of approval delays is \"manager wasn't at their computer.\"\n\n## Background\nv1 approvals happen in Slack. Mobile experience is poor. This adds a dedicated PWA that's optimized for mobile.\n\n## Technical Considerations\n- PWA: works on iOS Safari, Android Chrome\n- Push notifications: native notifications for new approvals\n- Offline support: view pending, cached data\n- Auth: same Slack OAuth, or simple magic link\n- UI: large touch targets, readable on small screens\n- Deal context: customer history, margin, competitive info\n- Quick actions: Approve, Reject, Need Info (asks rep questions)\n- Snooze: remind me later\n\n## User Experience\nManager receives push notification:\n\"\ud83d\udd14 Approval Request: Acme Corp - $21,420 (15% discount)\"\n\nOpens PWA:\n```\nApproval Request\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nCustomer: Acme Corp\nDeal: $21,420/yr\nDiscount: 15% (exceeds 10% cap)\nMargin: 62%\n\nContext:\n\u2022 14 month customer, 98% utilization\n\u2022 +50 seats expansion\n\u2022 Competitor X offered 20% discount\n\n[ Approve ] [ Reject ] [ Need Info ]\n```\n\n## Goals\n1. PWA works on iOS and Android\n2. Push notifications for new approvals\n3. Full deal context on mobile\n4. One-tap approve/reject\n5. \"Need Info\" option\n6. Offline viewing\n7. Biometric auth option (FaceID/TouchID)\n\n## Dependencies\n- Slack integration (exists in v1)\n- Approval workflow (exists in v1)\n- Account/Deal data (exists in v1)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #8]", "labels": ["v2", "mobile", "approvals", "pwa", "epic", "unblocking"]}
{"id": "quotey-009", "title": "EPIC-V2-ANALYTICS: Built-in Analytics Dashboard", "status": "open", "priority": 2, "issue_type": "epic", "created_at": "2026-02-26T11:08:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:08:00Z", "description": "## Overview\nNative dashboard showing: win rate by price range, average discount by rep/segment, quote-to-close velocity, margin trends, most-quoted products, approval bottleneck analysis. No external BI tool required.\n\n## Why This Matters\nSales leadership always asks \"how are we doing on pricing?\" Currently requires data team or manual analysis. This answers questions instantly. Shows pricing health at a glance. Identifies bottlenecks in approval process.\n\n## Background\nNot planned in v1. Adding native analytics on top of existing quote data.\n\n## Technical Considerations\n- Dashboard UI: charts, tables, filters\n- Metrics:\n  - Win rate by price range\n  - Average discount by rep/segment/region\n  - Quote-to-close velocity (days)\n  - Margin trends over time\n  - Most-quoted products\n  - Approval bottleneck analysis (who delays?)\n  - Discount distribution\n  - Deal size distribution\n- Filters: date range, segment, rep, product\n- Export: CSV download\n- Scheduling: weekly email digest option\n\n## Dashboard Sections\n\n### Pricing Health\n- Average discount by segment (bar chart)\n- Discount distribution (histogram)\n- Margin trends (line chart)\n\n### Velocity\n- Average quote-to-close by week (line chart)\n- Quotes in flight by age\n\n### Products\n- Most quoted products (table)\n- Bundle attach rate\n\n### Approvals\n- Approval turnaround time by approver\n- Bottleneck analysis\n- Auto-approval rate\n\n## User Experience\nRep opens \"/quotey analytics\" in Slack:\n```\n\ud83d\udcca Quotey Analytics\n\nPricing Health:\n\u2022 Avg discount: 12% (\u2191 2% from last month)\n\u2022 Avg margin: 68%\n\nVelocity:\n\u2022 Avg quote-to-close: 4.2 days\n\u2022 12 quotes in flight\n\nTop Products:\n1. Pro Plan (45%)\n2. SSO Add-on (28%)\n\n[ View Full Dashboard ]\n```\n\nOr open dedicated dashboard URL for full view.\n\n## Goals\n1. Pricing health metrics\n2. Velocity metrics\n3. Product analytics\n4. Approval analytics\n5. Filter by date/segment/rep\n6. Export to CSV\n7. Scheduled digests\n\n## Dependencies\n- Quote data (exists in v1)\n- Approval data (exists in v1)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #9]", "labels": ["v2", "analytics", "dashboard", "visibility", "epic"]}
{"id": "quotey-010", "title": "EPIC-V2-CRM: One-Click CRM Sync", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:09:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:09:00Z", "description": "## Overview\nBidirectional sync with Salesforce/HubSpot - quote status changes flow back to the CRM opportunity, deal amount updates automatically, customer data stays fresh. No manual re-entry. Single click to connect.\n\n## Why This Matters\nThe #1 friction point in CPQ is data entry. Reps quote in Quotey but then have to manually update Salesforce/HubSpot. This eliminates double data entry. Deal data is always current in both systems.\n\n## Background\nv1 has Composio integration stubbed. This makes it production-ready with one-click connect.\n\n## Technical Considerations\n- OAuth flow: one-click connect to Salesforce/HubSpot\n- Sync direction:\n  - Quotey \u2192 CRM: quote created, status changed, finalized, approved\n  - CRM \u2192 Quotey: account updated, opportunity stage changed\n- Field mapping: configurable mapping between Quotey and CRM fields\n- Conflict resolution: CRM wins or Quotey wins (configurable)\n- Sync frequency: real-time (webhooks) or batch (hourly)\n- Error handling: retry with backoff, alert on failure\n- Audit trail: log all sync actions\n\n## Sync Events\n\n### Quotey \u2192 CRM\n- Quote created \u2192 create opportunity line item\n- Quote finalized \u2192 update opportunity amount, stage\n- Quote approved \u2192 post to CRM\n- Quote rejected \u2192 post to CRM\n- Quote expired \u2192 update opportunity\n\n### CRM \u2192 Quotey\n- Account updated \u2192 sync to Quotey account\n- Opportunity stage changed \u2192 update quote context\n- Contact added \u2192 sync to Quotey contacts\n\n## User Experience\nInitial setup:\n```\n/quotey crm connect\n\nSelect CRM:\n[ Salesforce ] [ HubSpot ]\n\n\u2192 Redirects to OAuth\n\u2192 Returns with connection confirmed\n\n[ Configure Field Mapping ] [ Done ]\n```\n\nOngoing:\n```\nQuote Q-2026-0042 finalized.\n\u2192 Syncing to Salesforce...\n\u2192 \u2713 Opportunity updated (amount: $20,400)\n\u2192 \u2713 Line items synced\n```\n\n## Goals\n1. One-click OAuth connect to Salesforce\n2. One-click OAuth connect to HubSpot\n3. Bidirectional quote sync\n4. Configurable field mapping\n5. Real-time sync via webhooks\n6. Batch sync fallback\n7. Error handling with retry\n8. Full sync audit trail\n\n## Dependencies\n- Composio integration (v1 has stub)\n- OAuth handling\n- Slack integration (for status messages)\n\n[Created from: ultrathink feature ideation - TOP 10 IDEA #10]", "labels": ["v2", "crm", "integration", "sync", "epic", "productivity"]}
{"id": "quotey-001-1", "title": "TASK: Research MCP protocol and existing SDKs", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:10:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:30:00Z", "parent": "quotey-001", "description": "## Overview\nResearch Model Context Protocol specification, existing SDKs, and how other projects implement MCP servers. Determine best approach for Quotey.\n\n## Why This Matters\nNeed to understand the protocol before implementing. Avoid reinventing wheel by using existing libraries. Ensure approach aligns with MCP conventions for compatibility.\n\n## Tasks\n- Read MCP protocol specification\n- Find existing MCP server implementations (reference implementations)\n- Evaluate Rust MCP SDKs (if any)\n- Document findings and recommendation\n\n## Output\nTechnical recommendation document with:\n- Protocol overview\n- Recommended implementation approach\n- Estimated complexity\n- Dependencies needed\n\n[Created from: ultrathink - EPIC-V2-MCP subtask]", "labels": ["v2", "mcp", "research"], "assigned_to": "Kimi", "resolution": "completed", "completed_at": "2026-02-26T11:30:00Z"}
{"id": "quotey-001-2", "title": "TASK: Define MCP tool schema for Quotey", "status": "closed", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:11:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:35:00Z", "parent": "quotey-001", "description": "## Overview\nDefine the MCP tool schema - what tools/actions Quotey exposes to AI agents.\n\n## Why This Matters\nThe schema defines the contract between Quotey and AI agents. Must be comprehensive yet simple. Each tool needs clear inputs/outputs.\n\n## Tools to Define\n1. `catalog.search(query)` - Search products\n2. `catalog.get(product_id)` - Get product details\n3. `quote.create(customer_id, lines)` - Create new quote\n4. `quote.get(quote_id)` - Get quote details\n5. `quote.price(quote_id)` - Price a quote\n6. `quote.approve(quote_id)` - Request approval\n7. `quote.status(quote_id)` - Get approval status\n8. `quote.pdf(quote_id)` - Generate PDF\n9. `quote.list(filters)` - List quotes\n10. `approval.pending()` - Get pending approvals\n\n## Output\nJSON schema document for each tool with:\n- Tool name and description\n- Input parameters and types\n- Output format\n- Error cases\n\n[Created from: ultrathink - EPIC-V2-MCP subtask]", "labels": ["v2", "mcp", "schema", "api"], "assigned_to": "Kimi", "resolution": "completed", "completed_at": "2026-02-26T11:35:00Z"}
{"id": "quotey-001-3", "title": "TASK: Implement MCP server in Rust", "status": "in_progress", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:12:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:35:00Z", "parent": "quotey-001", "description": "## Overview\nImplement the MCP server that exposes Quotey capabilities to AI agents.\n\n## Why This Matters\nCore implementation of the MCP integration. Connects MCP protocol to existing Quotey functionality.\n\n## Implementation Details\n- Create new crate or module: `quotey-mcp`\n- Implement MCP protocol handler\n- Wire up each tool to existing Quotey functions\n- Add authentication (API key)\n- Add rate limiting\n- Add logging/audit\n\n## Technical Notes\n- Use existing Quotey functions (don't duplicate logic)\n- Ensure idempotency for retries\n- Handle errors gracefully with meaningful messages\n- Full audit trail for compliance\n\n[Created from: ultrathink - EPIC-V2-MCP subtask]", "labels": ["v2", "mcp", "implementation", "rust"], "assigned_to": "Kimi"}
{"id": "quotey-001-4", "title": "TASK: Add MCP authentication and rate limiting", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:13:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:13:00Z", "parent": "quotey-001", "description": "## Overview\nAdd authentication (API key) and rate limiting to MCP server.\n\n## Why This Matters\nEnterprise requirements. Prevent abuse. Ensure fair usage.\n\n## Authentication\n- API key header validation\n- Configurable in quotey.toml\n- Key rotation support\n\n## Rate Limiting\n- Per-key rate limits\n- Configurable limits (requests/minute)\n- 429 response with retry-after\n\n[Created from: ultrathink - EPIC-V2-MCP subtask]", "labels": ["v2", "mcp", "security", "auth"]}
{"id": "quotey-001-5", "title": "TASK: Test MCP server with AI agents", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:14:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:14:00Z", "parent": "quotey-001", "description": "## Overview\nTest MCP server integration with Claude Code and other AI agents.\n\n## Why This Matters\nVerify it works with real agents. Document usage. Fix issues found.\n\n## Test Cases\n1. Claude Code queries product catalog\n2. Claude Code creates and prices a quote\n3. Claude Code checks approval status\n4. Claude Code triggers PDF generation\n5. Verify audit trail completeness\n\n[Created from: ultrathink - EPIC-V2-MCP subtask]", "labels": ["v2", "mcp", "testing", "qa"]}
{"id": "quotey-002-1", "title": "TASK: Design similarity scoring algorithm", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:15:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:15:00Z", "parent": "quotey-002", "description": "## Overview\nDesign the algorithm that determines which products to suggest for a customer.\n\n## Why This Matters\nThe core of the recommendation engine. Must balance relevance with diversity. Should be explainable.\n\n## Algorithm Components\n1. **Customer similarity**: Find similar customers (segment, industry, size)\n2. **Purchase patterns**: What did similar customers buy?\n3. **Product relationships**: Bundles, add-ons, replacements\n4. **Time factors**: Seasonal trends, recent popularity\n5. **Business rules**: Always suggest X for segment Y\n\n## Scoring Formula\n```\nscore = (similar_customer_buy * 0.4) +\n        (product_relationship * 0.3) +\n        (time_decay * 0.2) +\n        (business_rule_boost * 0.1)\n```\n\n## Output\nAlgorithm design doc with:\n- Component definitions\n- Scoring formula\n- Weight rationale\n- Examples\n\n[Created from: ultrathink - EPIC-V2-SUGGEST subtask]", "labels": ["v2", "recommendations", "algorithm", "design"]}
{"id": "quotey-002-2", "title": "TASK: Implement product suggestion engine", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:16:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:16:00Z", "parent": "quotey-002", "description": "## Overview\nImplement the suggestion engine that generates product recommendations.\n\n## Why This Matters\nCore implementation. Connects algorithm to data and exposes suggestions via API.\n\n## Implementation\n- Create `suggestions` module\n- Implement similarity scoring\n- Implement product relationship lookup\n- Implement time-decay factors\n- Cache suggestions (refresh hourly)\n\n## API\n```rust\npub async fn get_suggestions(\n    customer_id: &str,\n    context: &QuoteContext,\n) -> Vec<ProductSuggestion>;\n```\n\n[Created from: ultrathink - EPIC-V2-SUGGEST subtask]", "labels": ["v2", "recommendations", "implementation", "engine"]}
{"id": "quotey-002-3", "title": "TASK: Add suggestion UI to Slack", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:17:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:17:00Z", "parent": "quotey-002", "description": "## Overview\nAdd suggestion display to Slack - show suggestions when rep selects customer.\n\n## Why This Matters\nUser-facing feature. Makes suggestions visible and actionable.\n\n## UI Design\n```\n\ud83d\udca1 Suggestions for Acme Corp\n\n1. Premium Support (85% match)\n   \"Enterprise customers typically add in year 1\"\n   [ Add to Quote ]\n\n2. SSO Add-on (72% match)\n   \"3 of 5 similar FinTech customers added\"\n   [ Add to Quote ]\n\n3. Onboarding Package (65% match)\n   \"Recommended for 150+ seats\"\n   [ Add to Quote ]\n```\n\n[Created from: ultrathink - EPIC-V2-SUGGEST subtask]", "labels": ["v2", "recommendations", "slack", "ui"]}
{"id": "quotey-002-4", "title": "TASK: Add feedback loop for suggestions", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:18:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:18:00Z", "parent": "quotey-002", "description": "## Overview\nTrack which suggestions are accepted/rejected to improve algorithm over time.\n\n## Why This Matters\nContinuous improvement. The system gets better as it learns from user behavior.\n\n## Feedback to Track\n- Suggestion shown\n- Clicked (viewed details)\n- Added to quote\n- Rejected/hidden\n\n## Updates\n- Re-score products based on feedback\n- Adjust weights over time\n- A/B test different algorithms\n\n[Created from: ultrathink - EPIC-V2-SUGGEST subtask]", "labels": ["v2", "recommendations", "feedback", "improvement"]}
{"id": "quotey-003-1", "title": "TASK: Design web portal architecture", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:19:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:19:00Z", "parent": "quotey-003", "description": "## Overview\nDesign the web portal architecture - how it serves quotes and handles customer interactions.\n\n## Why This Matters\nTechnical foundation. Need to decide on server approach, URL scheme, security model.\n\n## Architecture Options\n1. **Embedded**: Serve static HTML/JS from Quotey binary\n2. **Separate**: Standalone web service\n3. **Hybrid**: Embedded with optional external server\n\n## Decision: Embedded\n- Serve from Quotey binary (Axum)\n- Single binary deployment\n- No separate infrastructure\n- Customer URLs: http://rep-machine:3847/quote/abc123\n\n## URL Structure\n- `/quote/{token}` - View quote\n- `/quote/{token}/approve` - Approve\n- `/quote/{token}/reject` - Reject\n- `/quote/{token}/comment` - Add comment\n\n## Security\n- Token-based access (no auth)\n- Tokens expire (configurable)\n- Optional password for sensitive deals\n- Rate limiting\n\n[Created from: ultrathink - EPIC-V2-PORTAL subtask]", "labels": ["v2", "portal", "architecture", "design"]}
{"id": "quotey-003-2", "title": "TASK: Implement quote viewer page", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:20:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:20:00Z", "parent": "quotey-003", "description": "## Overview\nImplement the main quote viewer page - the page customers see when they open the link.\n\n## Why This Matters\nCore user experience. Must be clear, professional, and interactive.\n\n## Features\n- Quote header (company, quote number, date)\n- Customer info\n- Line items table with pricing\n- Totals section\n- Download PDF button\n- Approve/Reject buttons\n- Comments section\n\n## UI Requirements\n- Mobile responsive\n- Fast loading\n- Professional design\n- Accessible (WCAG)\n\n[Created from: ultrathink - EPIC-V2-PORTAL subtask]", "labels": ["v2", "portal", "ui", "implementation"]}
{"id": "quotey-003-3", "title": "TASK: Implement electronic approval capture", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:21:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:21:00Z", "parent": "quotey-003", "description": "## Overview\nImplement electronic approval - customer clicks to approve/reject with timestamp.\n\n## Why This Matters\nKey feature. Captures explicit approval for audit trail.\n\n## Approval Flow\n1. Customer clicks \"Approve\"\n2. Modal appears with summary\n3. Customer confirms\n4. Timestamp recorded\n5. Quotey notified\n6. Slack message to rep\n\n## Data Captured\n- Approver name (from form)\n- Approver email\n- Timestamp (UTC)\n- IP address (for audit)\n- Quote version approved\n\n[Created from: ultrathink - EPIC-V2-PORTAL subtask]", "labels": ["v2", "portal", "approval", "implementation"]}
{"id": "quotey-003-4", "title": "TASK: Add comment functionality", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:22:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:22:00Z", "parent": "quotey-003", "description": "## Overview\nAllow customers to add comments on specific line items or overall quote.\n\n## Why This Matters\nEnables clarification. Customer can ask questions without emailing rep.\n\n## Implementation\n- Comment form on each line item\n- Overall quote comments\n- Notifications to rep in Slack\n- Threaded replies\n\n[Created from: ultrathink - EPIC-V2-PORTAL subtask]", "labels": ["v2", "portal", "comments", "implementation"]}
{"id": "quotey-003-5", "title": "TASK: Implement link management and expiration", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:23:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:23:00Z", "parent": "quotey-003", "description": "## Overview\nManage shareable links - generation, expiration, revocation.\n\n## Why This Matters\nSecurity. Links shouldn't work forever.\n\n## Features\n- Generate unique tokens\n- Configurable expiration (default 30 days)\n- Manual revocation\n- View active links\n- Regenerate link (invalidates old)\n\n[Created from: ultrathink - EPIC-V2-PORTAL subtask]", "labels": ["v2", "portal", "security", "links"]}
{"id": "quotey-004-1", "title": "TASK: Design rule builder UI schema", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:24:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:24:00Z", "parent": "quotey-004", "description": "## Overview\nDesign the data schema for visual rule building - how rules are represented.\n\n## Why This Matters\nFoundation for builder UI. Must support all rule types and be serializable to SQLite.\n\n## Schema Design\n```rust\nstruct VisualRule {\n    name: String,\n    rule_type: RuleType, // pricing, constraint, policy, threshold\n    conditions: Vec<Condition>,\n    actions: Vec<Action>,\n    metadata: RuleMetadata,\n}\n\nstruct Condition {\n    field: String,\n    operator: Operator, // equals, not_equals, greater_than, etc.\n    value: serde_json::Value,\n    connector: Option<Connector>, // and, or\n}\n\nstruct Action {\n    action_type: ActionType,\n    parameters: HashMap<String, serde_json::Value>,\n}\n```\n\n[Created from: ultrathink - EPIC-V2-RULES subtask]", "labels": ["v2", "rules", "schema", "design"]}
{"id": "quotey-004-2", "title": "TASK: Implement pricing rule builder", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:25:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:25:00Z", "parent": "quotey-004", "description": "## Overview\nBuild the visual UI for creating pricing rules in Slack modals.\n\n## Why This Matters\nCore feature. Allows non-technical users to create pricing rules.\n\n## UI Flow\n1. Select rule type: \"Pricing Rule\"\n2. Enter name and description\n3. Add conditions (field \u2192 operator \u2192 value)\n4. Add action (set price, apply discount, etc.)\n5. Preview SQL generated\n6. Test with sample data\n7. Save to SQLite\n\n## Condition Builder\n```\nIF [customer_segment] [equals] [Enterprise]\nAND [region] [equals] [US]\nTHEN [base_price] [=] [$10.00]\n```\n\n[Created from: ultrathink - EPIC-V2-RULES subtask]", "labels": ["v2", "rules", "ui", "pricing"]}
{"id": "quotey-004-3", "title": "TASK: Implement constraint rule builder", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:26:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:26:00Z", "parent": "quotey-004", "description": "## Overview\nBuild the visual UI for creating constraint rules (requires, excludes, etc.).\n\n## Why This Matters\nEnables sales ops to manage product constraints without SQL.\n\n## Constraint Types\n- Requires: Product A requires Product B\n- Excludes: Product A excludes Product B\n- Attribute: Must satisfy condition\n- Quantity: Min/max quantities\n\n## UI Example\n```\nConstraint: SSO Add-on\nType: [Requires]\nTarget: [Enterprise Plan]\nMessage: \"SSO requires Enterprise tier\"\n```\n\n[Created from: ultrathink - EPIC-V2-RULES subtask]", "labels": ["v2", "rules", "ui", "constraints"]}
{"id": "quotey-004-4", "title": "TASK: Implement discount policy builder", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:27:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:27:00Z", "parent": "quotey-004", "description": "## Overview\nBuild the visual UI for creating discount policies.\n\n## Why This Matters\nCritical for deal desk. Controls how much discount is allowed without approval.\n\n## Policy Fields\n- Customer segment\n- Product category\n- Max discount (auto-approve)\n- Max discount (with approval)\n- Required approver role\n- Deal size filters\n\n[Created from: ultrathink - EPIC-V2-RULES subtask]", "labels": ["v2", "rules", "ui", "discount"]}
{"id": "quotey-004-5", "title": "TASK: Add rule preview and testing", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:28:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:28:00Z", "parent": "quotey-004", "description": "## Overview\nAllow admins to preview what a rule will do and test it against sample data before saving.\n\n## Why This Matters\nSafety. Don't let bad rules break production quotes.\n\n## Features\n- Show generated SQL\n- Run against sample quotes\n- Highlight affected quotes\n- Show before/after pricing\n\n[Created from: ultrathink - EPIC-V2-RULES subtask]", "labels": ["v2", "rules", "testing", "preview"]}
{"id": "quotey-005-1", "title": "TASK: Design requirement extraction prompt", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:29:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:29:00Z", "parent": "quotey-005", "description": "## Overview\nDesign the LLM prompt that extracts structured requirements from unstructured text.\n\n## Why This Matters\nCore of the auto-quote feature. Prompt quality determines extraction accuracy.\n\n## Prompt Requirements\n- Extract: products, quantities, features, billing preferences\n- Identify ambiguities\n- Confidence scoring\n- Return structured JSON\n\n## Output Format\n```json\n{\n  \"requirements\": [\n    {\n      \"type\": \"product\",\n      \"name\": \"Pro Plan\",\n      \"quantity\": 150,\n      \"confidence\": 0.95\n    }\n  ],\n  \"ambiguities\": [\n    {\n      \"text\": \"enterprise tier\",\n      \"question\": \"Did you mean Pro or Enterprise?\",\n      \"options\": [\"Pro Plan\", \"Enterprise Plan\"]\n    }\n  ],\n  \"missing_info\": [\"start date\"]\n}\n```\n\n[Created from: ultrathink - EPIC-V2-AUTOQUOTE subtask]", "labels": ["v2", "autoquote", "llm", "prompts"]}
{"id": "quotey-005-2", "title": "TASK: Implement email parser", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:30:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:30:00Z", "parent": "quotey-005", "description": "## Overview\nParse plain text emails to extract quote requirements.\n\n## Why This Matters\nCommon use case. Reps forward emails from customers asking for quotes.\n\n## Implementation\n- Use LLM for extraction (not regex)\n- Handle various email formats\n- Extract products, quantities, dates\n- Identify sender and context\n\n## Slack Command\n```\n/quote parse-email\n[forward email content]\n```\n\n[Created from: ultrathink - EPIC-V2-AUTOQUOTE subtask]", "labels": ["v2", "autoquote", "parser", "email"]}
{"id": "quotey-005-3", "title": "TASK: Implement RFP parser", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:31:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:31:00Z", "parent": "quotey-005", "description": "## Overview\nParse RFP documents to extract comprehensive quote requirements.\n\n## Why This Matters\nHigh-value feature. RFPs are complex and time-consuming to parse manually.\n\n## Complexity\n- Multiple sections (requirements, terms, evaluation)\n- Tables and lists\n- Quantities and specifications\n- Required vs optional features\n- Compliance requirements\n\n## Implementation\n- LLM with special prompting for RFPs\n- Table parsing\n- Section identification\n- Requirement categorization\n\n## Slack Command\n```\n/quote parse-rfp\n[paste RFP content or attach PDF]\n```\n\n[Created from: ultrathink - EPIC-V2-AUTOQUOTE subtask]", "labels": ["v2", "autoquote", "parser", "rfp"]}
{"id": "quotey-005-4", "title": "TASK: Implement product matcher", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:32:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:32:00Z", "parent": "quotey-005", "description": "## Overview\nMatch extracted requirements to actual products in the catalog.\n\n## Why This Matters\nCore linking. Requirements \u2192 products = draft quote.\n\n## Matching Logic\n1. Fuzzy name matching\n2. Synonym handling\n3. Attribute mapping\n4. Confidence scoring\n5. Ambiguity detection\n\n## Example\n- Extracted: \"SSO integration\"\n- Matched: \"SSO Add-on\" (95% confidence)\n- Alternative: \"Enterprise SSO\" (78%)\n\n[Created from: ultrathink - EPIC-V2-AUTOQUOTE subtask]", "labels": ["v2", "autoquote", "matching", "products"]}
{"id": "quotey-005-5", "title": "TASK: Implement draft quote builder", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:33:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:33:00Z", "parent": "quotey-005", "description": "## Overview\nCreate draft quote from matched products and extracted requirements.\n\n## Why This Matters\nCompletes the flow. Matched products \u2192 quoted = draft.\n\n## Draft Creation\n- Create quote in \"draft\" state\n- Add matched products as lines\n- Apply default quantities\n- Set status to needs_review\n- Present to rep for confirmation\n\n[Created from: ultrathink - EPIC-V2-AUTOQUOTE subtask]", "labels": ["v2", "autoquote", "draft", "implementation"]}
{"id": "quotey-006-1", "title": "TASK: Define anomaly detection rules", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:34:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:34:00Z", "parent": "quotey-006", "description": "## Overview\nDefine the specific anomaly detection rules and thresholds.\n\n## Why This Matters\nFoundation. What constitutes an anomaly?\n\n## Anomaly Types & Rules\n\n### Discount Anomaly\n- Flag if: discount > 2 * customer_avg + 1 std_dev\n- Warning threshold: 1.5 * avg\n- Critical threshold: 3 * avg\n\n### Margin Anomaly\n- Flag if: margin < product_category_floor\n- Warning: floor + 5%\n- Critical: below floor\n\n### Config Anomaly\n- Flag if: quantity > 3 * customer_avg\n- Flag if: new product (first time ordered)\n\n### Price Anomaly\n- Flag if: total > 1.5 * similar_deals_avg\n- Similar = same products + segment + region\n\n[Created from: ultrathink - EPIC-V2-ANOMALY subtask]", "labels": ["v2", "anomaly", "rules", "design"]}
{"id": "quotey-006-2", "title": "TASK: Implement anomaly detection engine", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:35:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:35:00Z", "parent": "quotey-006", "description": "## Overview\nImplement the engine that evaluates quotes against anomaly rules.\n\n## Why This Matters\nCore implementation. Runs on every quote before finalization.\n\n## Implementation\n- Create `anomaly` module\n- Calculate historical baselines\n- Run each rule\n- Return flagged items with severity\n- Cache baselines (refresh daily)\n\n## API\n```rust\npub async fn detect_anomalies(\n    quote: &Quote,\n) -> Vec<AnomalyFlag>;\n```\n\n[Created from: ultrathink - EPIC-V2-ANOMALY subtask]", "labels": ["v2", "anomaly", "implementation", "engine"]}
{"id": "quotey-006-3", "title": "TASK: Add anomaly UI to quote flow", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:36:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:36:00Z", "parent": "quotey-006", "description": "## Overview\nIntegrate anomaly detection into quote finalization flow.\n\n## Why This Matters\nUser-facing. Makes anomalies visible and actionable.\n\n## Flow\n1. Rep clicks \"Finalize Quote\"\n2. System runs anomaly detection\n3. If anomalies found \u2192 show warning modal\n4. Rep can override or adjust\n5. Override requires justification\n\n## UI\n```\n\u26a0\ufe0f Quote flagged for review\n\n\u2022 Discount (18%) is 2.3x your average\n\u2022 Margin (52%) below SaaS floor (60%)\n\n[ Override ] [ Adjust Quote ]\n```\n\n[Created from: ultrathink - EPIC-V2-ANOMALY subtask]", "labels": ["v2", "anomaly", "ui", "slack"]}
{"id": "quotey-006-4", "title": "TASK: Add override with justification", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:37:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:37:00Z", "parent": "quotey-006", "description": "## Overview\nAllow reps to override anomaly flags with justification.\n\n## Why This Matters\nFlexibility. Not all anomalies are bad.\n\n## Implementation\n- Require text justification\n- Log override in audit\n- Notify manager of override\n- Track override rate by rep\n\n[Created from: ultrathink - EPIC-V2-ANOMALY subtask]", "labels": ["v2", "anomaly", "override", "audit"]}
{"id": "quotey-007-1", "title": "TASK: Design 5 quote templates", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:38:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:38:00Z", "parent": "quotey-007", "description": "## Overview\nDesign 5 distinct quote templates for different use cases.\n\n## Why This Matters\nCore content. Templates define the PDF output.\n\n## Templates\n\n### 1. Executive Summary\n- 1 page max\n- High-level: customer, total, term\n- Key line items only (top 3)\n- For: quick decisions, executive review\n\n### 2. Detailed\n- Full line items\n- All pricing breakdowns\n- Terms and conditions\n- For: procurement, legal review\n\n### 3. Comparison\n- Side-by-side product/price options\n- Option A vs Option B\n- For: multi-choice situations\n\n### 4. Renewal\n- Current vs proposed side-by-side\n- Change highlighting\n- For: renewal discussions\n\n### 5. Compact\n- Minimal format\n- Single page if possible\n- For: email attachment\n\n[Created from: ultrathink - EPIC-V2-PDF subtask]", "labels": ["v2", "pdf", "templates", "design"]}
{"id": "quotey-007-2", "title": "TASK: Implement template engine with branding", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:39:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:39:00Z", "parent": "quotey-007", "description": "## Overview\nImplement template system with customizable branding.\n\n## Why This Matters\nEnables white-label and customization.\n\n## Branding Options\n- Logo upload (PNG/JPG, stored in SQLite)\n- Primary color (for headers, accents)\n- Secondary color\n- Company name\n- Company address\n- Contact info\n- Footer text\n\n## Storage\n- Logo stored as base64 in config\n- Colors stored in quotey.toml or DB\n- Per-template overrides possible\n\n[Created from: ultrathink - EPIC-V2-PDF subtask]", "labels": ["v2", "pdf", "implementation", "branding"]}
{"id": "quotey-007-3", "title": "TASK: Implement logo upload UI", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:40:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:40:00Z", "parent": "quotey-007", "description": "## Overview\nAdd Slack UI for uploading and managing logos.\n\n## Why This Matters\nUser-facing. Admins need to set branding.\n\n## Slack Command\n```\n/quotey branding\n\n\u2192 Opens modal with:\n- Current logo preview\n- Upload new logo\n- Color pickers\n- Live preview\n- Save button\n```\n\n[Created from: ultrathink - EPIC-V2-PDF subtask]", "labels": ["v2", "pdf", "ui", "branding", "slack"]}
{"id": "quotey-007-4", "title": "TASK: Add white-label option", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:41:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:41:00Z", "parent": "quotey-007", "description": "## Overview\nAdd option to remove all Quotey branding for partners/resellers.\n\n## Why This Matters\nEnables white-label for partners.\n\n## White-Label Features\n- Remove \"Generated by Quotey\" footer\n- Custom sender name\n- Custom support contact\n- Custom terms footer\n\n[Created from: ultrathink - EPIC-V2-PDF subtask]", "labels": ["v2", "pdf", "whitelabel", "partner"]}
{"id": "quotey-008-1", "title": "TASK: Design PWA architecture", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:42:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:42:00Z", "parent": "quotey-008", "description": "## Overview\nDesign Progressive Web App architecture for mobile approvals.\n\n## Why This Matters\nFoundation. How PWA connects to Quotey?\n\n## Architecture\n- Static HTML/JS/CSS served from Quotey\n- API calls back to Quotey for data\n- Service worker for offline\n- Web App Manifest\n\n## URL Structure\n- `/approvals` - List pending\n- `/approvals/:id` - Detail view\n- `/settings` - Preferences\n\n## Tech Stack\n- Vanilla JS (no framework for simplicity)\n- Tailwind CSS (lightweight)\n- Service worker for offline\n\n[Created from: ultrathink - EPIC-V2-MOBILE subtask]", "labels": ["v2", "mobile", "pwa", "architecture"]}
{"id": "quotey-008-2", "title": "TASK: Implement approval list view", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:43:00Z", "parent": "quotey-008", "description": "## Overview\nImplement the main approval list view.\n\n## Why This Matters\nUser sees pending approvals at a glance.\n\n## UI\n```\n\ud83d\udccb Pending Approvals (3)\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\nAcme Corp - $21,420\n15% discount \u2022 62% margin\n2 hours ago\n\n[ View ]\n\nTechCorp - $45,000\n20% discount \u2022 58% margin\n5 hours ago\n\n[ View ]\n```\n\n[Created from: ultrathink - EPIC-V2-MOBILE subtask]", "labels": ["v2", "mobile", "ui", "approvals"]}
{"id": "quotey-008-3", "title": "TASK: Implement approval detail view", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:44:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:44:00Z", "parent": "quotey-008", "description": "## Overview\nImplement full approval detail with context.\n\n## Why This Matters\nManager needs all info to decide.\n\n## Data Shown\n- Customer info and history\n- Quote details (lines, pricing)\n- Discount impact\n- Margin analysis\n- Competitive context\n- Justification from rep\n- Similar deals\n\n## Actions\n- Approve (one tap)\n- Reject (with reason)\n- Need Info (asks rep)\n- Snooze (remind later)\n\n[Created from: ultrathink - EPIC-V2-MOBILE subtask]", "labels": ["v2", "mobile", "ui", "detail"]}
{"id": "quotey-008-4", "title": "TASK: Add push notifications", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:45:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:45:00Z", "parent": "quotey-008", "description": "## Overview\nImplement push notifications for new approvals.\n\n## Why This Matters\nCritical. Manager needs to know immediately.\n\n## Implementation\n- Use Web Push API\n- Subscribe on first visit\n- Push from Quotey when approval requested\n- Notification content: customer, amount, discount\n- Deep link to approval detail\n\n[Created from: ultrathink - EPIC-V2-MOBILE subtask]", "labels": ["v2", "mobile", "notifications", "push"]}
{"id": "quotey-008-5", "title": "TASK: Add biometric authentication", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:46:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:46:00Z", "parent": "quotey-008", "description": "## Overview\nAdd FaceID/TouchID support for quick authentication.\n\n## Why This Matters\nConvenience. One tap to authenticate.\n\n## Implementation\n- Use Web Authentication API\n- Register on first use\n- Prompt on each approval action\n- Fallback to password\n\n[Created from: ultrathink - EPIC-V2-MOBILE subtask]", "labels": ["v2", "mobile", "security", "biometric"]}
{"id": "quotey-009-1", "title": "TASK: Design analytics metrics and dimensions", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:47:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:47:00Z", "parent": "quotey-009", "description": "## Overview\nDefine the metrics and dimensions for the analytics dashboard.\n\n## Why This Matters\nFoundation. What are we measuring?\n\n## Metrics\n\n### Pricing Health\n- Average discount by segment\n- Average discount by rep\n- Discount distribution (% in each bucket)\n- Average margin by product\n- Margin distribution\n\n### Velocity\n- Quote creation to close (days)\n- Quote age (in flight)\n- Approval turnaround time\n- Time by stage\n\n### Products\n- Quote count by product\n- Attach rate (bundles/add-ons)\n- Popular bundles\n\n### Approvals\n- Approval rate\n- Rejection rate\n- Auto-approval rate\n- Bottleneck analysis (who delays)\n\n### Deals\n- Deal size distribution\n- Win rate by price range\n- Win rate by segment\n\n## Dimensions\n- Date (week, month, quarter, year)\n- Segment (SMB, Mid-Market, Enterprise)\n- Region (US, EU, APAC)\n- Rep\n- Product category\n\n[Created from: ultrathink - EPIC-V2-ANALYTICS subtask]", "labels": ["v2", "analytics", "metrics", "design"]}
{"id": "quotey-009-2", "title": "TASK: Implement analytics queries", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:48:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:48:00Z", "parent": "quotey-009", "description": "## Overview\nImplement SQL queries for analytics metrics.\n\n## Why This Matters\nCore implementation. Powers the dashboard.\n\n## Query Types\n- Aggregations (SUM, AVG, COUNT)\n- Grouping (by segment, rep, product)\n- Time series (trends over time)\n- Percentiles (distribution)\n- Comparisons (current vs previous period)\n\n## Performance\n- Pre-compute daily aggregates\n- Cache query results\n- Background refresh hourly\n\n[Created from: ultrathink - EPIC-V2-ANALYTICS subtask]", "labels": ["v2", "analytics", "queries", "sql"]}
{"id": "quotey-009-3", "title": "TASK: Build analytics dashboard UI", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:49:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:49:00Z", "parent": "quotey-009", "description": "## Overview\nBuild the analytics dashboard UI.\n\n## Why This Matters\nUser-facing. How users see the data.\n\n## Sections\n1. **Summary cards**: Key metrics at a glance\n2. **Pricing charts**: Discount and margin trends\n3. **Velocity**: Quote timing\n4. **Products**: Popular items\n5. **Approvals**: Bottlenecks\n\n## Tech\n- Embedded in Quotey (Axum)\n- Chart.js for visualizations\n- Responsive design\n- Slack link to open dashboard\n\n[Created from: ultrathink - EPIC-V2-ANALYTICS subtask]", "labels": ["v2", "analytics", "ui", "dashboard"]}
{"id": "quotey-009-4", "title": "TASK: Add export and scheduling", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:50:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:50:00Z", "parent": "quotey-009", "description": "## Overview\nAdd CSV export and email digest scheduling.\n\n## Why This Matters\nConsumption. Users want data in other formats.\n\n## Export\n- CSV export for all tables\n- Date range selection\n- Column selection\n\n## Scheduling\n- Weekly email digest\n- Configurable day/time\n- Include key metrics\n- Link to dashboard\n\n[Created from: ultrathink - EPIC-V2-ANALYTICS subtask]", "labels": ["v2", "analytics", "export", "scheduling"]}
{"id": "quotey-010-1", "title": "TASK: Implement Salesforce OAuth flow", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:51:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:51:00Z", "parent": "quotey-010", "description": "## Overview\nImplement one-click OAuth connection to Salesforce.\n\n## Why This Matters\nCore integration. Enables Salesforce sync.\n\n## OAuth Flow\n1. User clicks \"Connect Salesforce\"\n2. Redirect to Salesforce OAuth\n3. User approves\n4. Callback with auth code\n5. Exchange for access token\n6. Store tokens securely\n7. Test connection\n\n## Implementation\n- Use existing Composio integration\n- Or direct Salesforce OAuth\n- Store: access_token, refresh_token, instance_url\n- Token refresh handling\n\n[Created from: ultrathink - EPIC-V2-CRM subtask]", "labels": ["v2", "crm", "salesforce", "oauth"]}
{"id": "quotey-010-2", "title": "TASK: Implement HubSpot OAuth flow", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:52:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:52:00Z", "parent": "quotey-010", "description": "## Overview\nImplement one-click OAuth connection to HubSpot.\n\n## Why This Matters\nCore integration. Enables HubSpot sync.\n\n## OAuth Flow\nSame pattern as Salesforce\n- Redirect to HubSpot OAuth\n- User approves\n- Store tokens\n- Test connection\n\n[Created from: ultrathink - EPIC-V2-CRM subtask]", "labels": ["v2", "crm", "hubspot", "oauth"]}
{"id": "quotey-010-3", "title": "TASK: Implement quote sync (Quotey \u2192 CRM)", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:53:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:53:00Z", "parent": "quotey-010", "description": "## Overview\nSync quotes from Quotey to CRM.\n\n## Why This Matters\nCore sync. Keeps CRM up to date.\n\n## Events to Sync\n- Quote created \u2192 Create opportunity\n- Quote finalized \u2192 Update amount, stage\n- Quote approved \u2192 Post approval\n- Quote rejected \u2192 Post rejection\n- Quote expired \u2192 Update stage\n\n## Implementation\n- Webhook: real-time sync\n- Fallback: batch sync hourly\n- Conflict resolution: Quotey wins\n- Error handling with retry\n\n[Created from: ultrathink - EPIC-V2-CRM subtask]", "labels": ["v2", "crm", "sync", "implementation"]}
{"id": "quotey-010-4", "title": "TASK: Implement account sync (CRM \u2192 Quotey)", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:54:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:54:00Z", "parent": "quotey-010", "description": "## Overview\nSync account data from CRM to Quotey.\n\n## Why This Matters\nKeeps Quotey data fresh.\n\n## Events to Sync\n- Account updated \u2192 Sync to Quotey\n- Contact added \u2192 Sync to Quotey\n- Opportunity stage changed \u2192 Update quote context\n\n## Implementation\n- Webhook: real-time\n- Polling fallback\n- Deduplication by CRM ID\n\n[Created from: ultrathink - EPIC-V2-CRM subtask]", "labels": ["v2", "crm", "sync", "implementation"]}
{"id": "quotey-010-5", "title": "TASK: Implement field mapping UI", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:55:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:55:00Z", "parent": "quotey-010", "description": "## Overview\nAllow users to configure field mapping between Quotey and CRM.\n\n## Why This Matters\nFlexibility. Different CRMs have different fields.\n\n## UI\n```\n/quotey crm mapping\n\nQuotey \u2192 CRM:\nquote.total \u2192 Opportunity.Amount\nquote.discount \u2192 Opportunity.Discount\n\nCRM \u2192 Quotey:\nAccount.Industry \u2192 account.industry\n```\n\n[Created from: ultrathink - EPIC-V2-CRM subtask]", "labels": ["v2", "crm", "mapping", "ui"]}
{"id": "quotey-010-6", "title": "TASK: Add sync monitoring and error handling", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:56:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T11:56:00Z", "parent": "quotey-010", "description": "## Overview\nAdd monitoring, alerting, and error handling for CRM sync.\n\n## Why This Matters\nReliability. Need to know when sync fails.\n\n## Features\n- Sync status in Slack\n- Error alerts\n- Retry with backoff\n- Manual retry button\n- Sync history log\n\n[Created from: ultrathink - EPIC-V2-CRM subtask]", "labels": ["v2", "crm", "monitoring", "reliability"]}
{"id": "quotey-099-1", "title": "TASK: Add web server for portal/dashboard/PWA", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T12:00:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T12:00:00Z", "description": "## Overview\nAdd web server capability to Quotey for serving portal, dashboard, and PWA.\n\n## Why This Matters\nSeveral v2 features require web UI: Portal, Analytics, Mobile PWA. Need a common web server.\n\n## Implementation\n- Add Axum web server to Quotey\n- Serve static files\n- API endpoints for each feature\n- Configurable port (default 3847)\n- TLS support for production\n- Rate limiting\n\n## Dependencies\n- EPIC-V2-PORTAL\n- EPIC-V2-ANALYTICS\n- EPIC-V2-MOBILE\n\n[Created from: ultrathink - cross-cutting infrastructure]", "labels": ["v2", "infrastructure", "web", "axum"]}
{"id": "quotey-099-2", "title": "TASK: Design unified authentication system", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T12:01:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T12:01:00Z", "description": "## Overview\nDesign unified auth system for all v2 features (portal, MCP, mobile).\n\n## Why This Matters\nMultiple features need auth. Should be consistent.\n\n## Auth Types\n1. **MCP**: API key\n2. **Portal**: Token-based (link + optional password)\n3. **Mobile PWA**: OAuth (Slack) + optional biometric\n\n## Design\n- Unified token management\n- Consistent error responses\n- Audit logging\n- Token revocation\n\n[Created from: ultrathink - cross-cutting infrastructure]", "labels": ["v2", "security", "auth", "design"]}
{"id": "quotey-099-3", "title": "TASK: Performance optimization for scale", "status": "open", "priority": 3, "issue_type": "task", "created_at": "2026-02-26T12:02:00Z", "created_by": "ubuntuman", "updated_at": "2026-02-26T12:02:00Z", "description": "## Overview\nOptimize performance for handling larger data volumes.\n\n## Why This Matters\nv1 optimized for small scale. v2 features add load.\n\n## Areas\n- Query optimization (indexes, caching)\n- Background job processing\n- Rate limiting\n- Resource cleanup\n\n[Created from: ultrathink - cross-cutting infrastructure]", "labels": ["v2", "performance", "optimization"]}
{"id": "bd-pc", "title": "EPIC: Product Catalog Structure Overhaul", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## Problem\n\nThe current Product model is `{id, sku, name, active}` \u2014 a flat struct with no structure. The Catalog is a HashMap lookup with a single `find()` method. For CPQ to function as designed, products need structured attributes, hierarchical families, configurable option groups, and price book linkages.\n\n## Why This Is Foundational\n\nEvery other CPQ subsystem depends on rich product data:\n- The **constraint engine** needs product relationships (dependency/exclusion rules between products)\n- The **pricing engine** needs price book entries and tier definitions attached to products\n- The **policy engine** needs product families/segments to scope rules (e.g., \"premium products have lower max discount\")\n- The **agent** needs product attributes to match fuzzy NL descriptions to concrete ProductIds\n- The **DNA/similarity** system needs product structure to generate meaningful configuration fingerprints\n- The **catalog bootstrap** agent (a key differentiator per PROJECT.md) needs a target schema to ingest into\n\nWithout rich product data, the constraint engine has nothing to constrain, the pricing engine has nothing to price contextually, and the agent has nothing to suggest. This is the foundation layer that everything else builds on.\n\n## Architectural Principle\n\nProduct domain types live in `quotey-core` (no DB dependency). The repository layer in `quotey-db` handles persistence. The `Catalog` struct in `cpq/catalog.rs` serves as the in-memory runtime representation, populated at startup from the DB.\n\n## Current State\n\n- `crates/core/src/domain/product.rs`: ProductId(String), Product{id, sku, name, active}\n- `crates/core/src/cpq/catalog.rs`: Catalog with HashMap<ProductId, Product> and find() method\n- `crates/db/src/repositories/product.rs`: SqlProductRepository that returns errors (\"product catalog tables are not present\")\n- No product-related SQLite tables exist in the migration set\n\n## Success Criteria\n\n- Product domain model supports: attributes (typed key-value), families (hierarchical), option groups (configurable choices), relationships (bundle/recommend/supersede)\n- SqlProductRepository passes round-trip CRUD tests against in-memory SQLite\n- Catalog supports O(1) lookup by ID (already done), O(1) by family, attribute-based filtering\n- Demo seed data covers 5-10 products across 2-3 families with meaningful attributes and constraints\n- All existing 332 tests continue to pass (no breakage to current Product consumers)", "labels": ["cpq", "foundation", "product-catalog"]}
{"id": "bd-pc-1", "title": "Extend Product domain model with attributes, families, and option groups", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nAdd to `crates/core/src/domain/product.rs`:\n- `ProductAttribute` \u2014 typed key-value pairs: `{key: String, attr_type: AttributeType, value: AttributeValue}` where AttributeType is Enum/Text/Number/Boolean and AttributeValue matches. Example: `{key: \"deployment\", type: Enum, value: \"cloud\"}`.\n- `ProductFamily` \u2014 hierarchical grouping: `{id: ProductFamilyId, name: String, parent_family_id: Option<ProductFamilyId>}`. Example: \"Software > Plans > Enterprise Plan\".\n- `OptionGroup` \u2014 configurable choices within a product: `{id: OptionGroupId, product_id: ProductId, name: String, cardinality: Cardinality, choices: Vec<OptionChoice>}` where Cardinality is ExactlyOne/AtLeastOne/AtMostOne/Any. Example: \"Support Level\" with choices [Standard, Premium, Elite].\n- `ProductRelationship` \u2014 typed relationships: `{source_id: ProductId, target_id: ProductId, relationship_type: RelType}` where RelType is Bundle/Recommended/Supersedes.\n\n## Why\n\nThese types are the vocabulary the constraint engine, pricing engine, and agent use to reason about products. Without them, every subsystem operates on unstructured ProductIds with no semantic meaning.\n\n## Design Constraints\n\n- All types in `quotey-core` with no DB dependency (pure domain primitives)\n- Must derive: Clone, Debug, PartialEq, Eq, Serialize, Deserialize\n- ProductFamilyId and OptionGroupId should derive Hash for HashMap usage\n- No changes to existing Product struct (only additions alongside it)\n- The Product struct should gain: `attributes: Vec<ProductAttribute>`, `family_id: Option<ProductFamilyId>`, `option_groups: Vec<OptionGroup>`, `relationships: Vec<ProductRelationship>`\n\n## Isomorphism Note\n\nAdding fields to Product requires updating all existing test fixtures that create Product instances. However, the new fields should all be `Vec::new()` or `None` for backward compatibility. Existing logic that only accesses `id/sku/name/active` is unaffected.", "labels": ["cpq", "domain-model", "product-catalog"], "parent": "bd-pc"}
{"id": "bd-pc-2", "title": "Create product catalog SQLite schema (migration)", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nMigration file in `migrations/` that creates tables for the enriched product model:\n\n```sql\n-- Product attributes (typed key-value pairs attached to products)\nCREATE TABLE product_attribute (\n    id TEXT PRIMARY KEY,\n    product_id TEXT NOT NULL REFERENCES product(id),\n    attribute_key TEXT NOT NULL,\n    attribute_type TEXT NOT NULL,  -- 'enum', 'text', 'number', 'boolean'\n    attribute_value TEXT NOT NULL,\n    created_at TEXT NOT NULL,\n    updated_at TEXT NOT NULL,\n    UNIQUE(product_id, attribute_key)\n);\n\n-- Product families (hierarchical grouping)\nCREATE TABLE product_family (\n    id TEXT PRIMARY KEY,\n    name TEXT NOT NULL,\n    parent_family_id TEXT REFERENCES product_family(id),\n    created_at TEXT NOT NULL\n);\n\n-- Family membership (products belong to families)\nALTER TABLE product ADD COLUMN family_id TEXT REFERENCES product_family(id);\n\n-- Option groups (configurable choices within a product)\nCREATE TABLE option_group (\n    id TEXT PRIMARY KEY,\n    product_id TEXT NOT NULL REFERENCES product(id),\n    name TEXT NOT NULL,\n    cardinality TEXT NOT NULL DEFAULT 'exactly_one',\n    created_at TEXT NOT NULL\n);\n\nCREATE TABLE option_choice (\n    id TEXT PRIMARY KEY,\n    option_group_id TEXT NOT NULL REFERENCES option_group(id),\n    name TEXT NOT NULL,\n    sku TEXT,\n    price_delta TEXT,  -- additional cost for this choice\n    sort_order INTEGER NOT NULL DEFAULT 0,\n    created_at TEXT NOT NULL\n);\n\n-- Product relationships\nCREATE TABLE product_relationship (\n    id TEXT PRIMARY KEY,\n    source_product_id TEXT NOT NULL REFERENCES product(id),\n    target_product_id TEXT NOT NULL REFERENCES product(id),\n    relationship_type TEXT NOT NULL,  -- 'bundle', 'recommended', 'supersedes'\n    created_at TEXT NOT NULL,\n    UNIQUE(source_product_id, target_product_id, relationship_type)\n);\n```\n\n## Seed Data\n\nInclude demo data for the standard Quotey product catalog: Enterprise Plan, Pro Plan, Basic Plan, SSO Add-on, Premium Support, Standard Support, Onboarding, API Access. Organize into families: Plans, Add-ons, Services. Add attributes: deployment (cloud/on-prem/hybrid), region (US/EU/APAC), tier (enterprise/mid-market/smb).\n\n## Dependencies\n\nDepends on bd-pc-1 (domain model must be defined first so migration aligns with Rust types).", "labels": ["cpq", "database", "migration", "product-catalog"], "parent": "bd-pc"}
{"id": "bd-pc-3", "title": "Implement SqlProductRepository with full CRUD and catalog loading", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nReplace the stub in `crates/db/src/repositories/product.rs` (which currently returns `RepositoryError::Decode(\"SqlProductRepository is unavailable\")`) with a working implementation.\n\n## Methods\n\n- `find_by_id(id)` \u2014 load product with attributes, family, option groups in a single JOIN query (avoid N+1)\n- `save(product)` \u2014 upsert product and all related data in a transaction\n- `list_all()` \u2014 load all active products with attributes (used to populate Catalog at startup)\n- `find_by_family(family_id)` \u2014 products in a given family\n- `find_by_attribute(key, value)` \u2014 products matching an attribute filter\n- `list_option_groups(product_id)` \u2014 option groups for a product\n\n## Critical Design Decision: JOIN Strategy\n\nThe `list_all()` method is called at startup to populate the in-memory Catalog. It MUST use a single query with JOINs rather than N+1 queries per product. Pattern:\n\n```sql\nSELECT p.*, pa.attribute_key, pa.attribute_type, pa.attribute_value,\n       pf.name as family_name\nFROM product p\nLEFT JOIN product_attribute pa ON pa.product_id = p.id\nLEFT JOIN product_family pf ON pf.id = p.family_id\nWHERE p.active = 1\nORDER BY p.id\n```\n\nThen group rows by product_id in Rust code to reconstruct Product structs with their attributes.\n\n## Testing\n\nRound-trip tests against in-memory SQLite (pattern established in `quote.rs`). Test: save \u2192 find_by_id returns identical data. Test: list_all returns all active products. Test: find_by_family filters correctly.\n\n## Dependencies\n\nDepends on bd-pc-1 (domain model) and bd-pc-2 (schema).", "labels": ["cpq", "database", "repository", "product-catalog"], "parent": "bd-pc"}
{"id": "bd-pc-4", "title": "Enrich Catalog with attribute filtering and family-aware queries", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nExtend `crates/core/src/cpq/catalog.rs` Catalog to support:\n- `find_by_family(family_id) -> Vec<&Product>` \u2014 products in a family\n- `find_by_attribute(key, value) -> Vec<&Product>` \u2014 products with matching attribute\n- `list_option_groups(product_id) -> Vec<&OptionGroup>` \u2014 option groups for a product\n- `get_relationships(product_id) -> Vec<&ProductRelationship>` \u2014 relationships for a product\n\n## Implementation\n\nThe Catalog (recently optimized to HashMap<ProductId, Product>) should add secondary indexes built at construction time:\n- `family_index: HashMap<ProductFamilyId, Vec<ProductId>>`\n- `attribute_index: HashMap<(String, String), Vec<ProductId>>` \u2014 key: (attribute_key, attribute_value), value: product IDs\n\nThese indexes enable O(1) lookup by family and O(1) lookup by attribute, matching the existing O(1) by-ID performance.\n\n## Why\n\nThe constraint engine needs `find_by_family` to evaluate group-level constraints. The agent needs `find_by_attribute` to match fuzzy NL descriptions (\"I need an enterprise cloud product\" \u2192 find_by_attribute(\"deployment\", \"cloud\") \u2229 find_by_attribute(\"tier\", \"enterprise\")). The pricing engine needs option groups to price configurable products.\n\n## Dependencies\n\nDepends on bd-pc-1 (domain model) and bd-pc-3 (repository, for the data source).", "labels": ["cpq", "product-catalog"], "parent": "bd-pc"}
{"id": "bd-ce", "title": "EPIC: Constraint Engine - From Validator to Configuration Solver", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## Problem\n\nThe constraint engine currently does data hygiene checks: empty quotes, missing product IDs, duplicate products, zero quantity, non-positive prices. These are input validation, not product configuration constraints.\n\nPROJECT.md specifies: \"Deterministic constraint-based product configuration engine with dependency/exclusion rules\" and cites: \"Rules-based systems suffer combinatorial explosion at scale; constraints reduce thousands of rules to hundreds of constraints (Tacton case study).\"\n\nNone of that exists. There are no dependency rules (\"Enterprise Plan requires SSO\"), no exclusion rules (\"Basic and Premium are mutually exclusive\"), no cardinality bounds, no attribute-conditional constraints.\n\n## Why This Matters\n\nThe constraint engine is the architectural differentiator between Quotey and rules-based CPQ tools. Without it:\n- The agent can't prevent invalid configurations before pricing\n- The agent can't suggest what to add next (no forward checking)\n- Reps can create quotes with impossible configurations, wasting time\n- The \"constraint-based\" positioning in PROJECT.md is hollow\n\n## Target Architecture\n\n1. **Constraint rules as SQLite data** \u2014 not hardcoded Rust match statements\n2. **Constraint types**: Requires, Excludes, RequiresOneOf, Cardinality, AttributeConstraint\n3. **Forward checking**: Given current config, compute what's still valid to add\n4. **Suggestion generation**: When violations occur, suggest specific resolutions\n5. **Integration point**: The agent's slot-filling loop queries the constraint engine after each product addition\n\n## Interaction with Other Systems\n\n- **Product Catalog** (dependency): Constraints reference ProductIds and ProductFamilyIds \u2014 needs the enriched product model\n- **Agent Runtime** (consumer): The agent calls `valid_additions()` to suggest products and `suggest_resolution()` to handle violations\n- **Flow Engine** (consumer): FlowState transition from Draft\u2192Validated calls constraint validation\n- **Pricing Engine** (sequencing): Constraints are checked BEFORE pricing \u2014 invalid configs are never priced\n- **CLO** (future): Constraint rules may be optimized similarly to policy rules\n\n## Preserving Current Behavior\n\nThe existing data hygiene checks (empty quote, missing product ID, zero quantity, non-positive price) must be preserved as they are. New constraint rules are additive \u2014 they add capabilities without removing existing validation.", "labels": ["cpq", "constraints", "foundation"]}
{"id": "bd-ce-1", "title": "Define constraint rule domain model", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nCreate constraint rule types in `crates/core/src/domain/` (new file or extend existing):\n\n```rust\npub enum ConstraintType {\n    /// Product A requires Product B to be present\n    Requires { source: ProductId, target: ProductId },\n    /// Product A and Product B cannot coexist\n    Excludes { product_a: ProductId, product_b: ProductId },\n    /// Product A requires at least one of the target group\n    RequiresOneOf { source: ProductId, target_group: ProductFamilyId },\n    /// At most/least N products from a group\n    Cardinality { group: ProductFamilyId, min: u32, max: u32 },\n    /// Conditional: if attribute matches, require another product\n    AttributeConstraint { condition: AttributeCondition, required: ProductId },\n}\n\npub struct ConstraintRule {\n    pub id: ConstraintRuleId,\n    pub constraint_type: ConstraintType,\n    pub error_message: String,      // User-facing: \"Enterprise Plan requires SSO Add-on\"\n    pub suggestion_message: String,  // User-facing: \"Add SSO Add-on to continue\"\n    pub priority: u32,               // Evaluation order (lower = first)\n    pub active: bool,\n}\n\npub struct AttributeCondition {\n    pub attribute_key: String,\n    pub operator: ComparisonOperator,  // Eq, Neq, Contains\n    pub value: String,\n}\n```\n\n## Design for Efficient Lookup\n\nThe constraint engine needs to quickly find \"all rules that reference product X.\" Design the data model so rules can be indexed by both source and target product IDs. Use a `Vec<ProductId>` accessor method on ConstraintType that returns all referenced product IDs \u2014 the engine uses this to build a lookup index.\n\n## Dependencies\n\nDepends on bd-pc-1 (ProductId, ProductFamilyId types from enriched product model).", "labels": ["cpq", "constraints", "domain-model"], "parent": "bd-ce"}
{"id": "bd-ce-2", "title": "Create constraint rules SQLite schema", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nMigration creating the `constraint_rule` table:\n\n```sql\nCREATE TABLE constraint_rule (\n    id TEXT PRIMARY KEY,\n    constraint_type TEXT NOT NULL,  -- 'requires', 'excludes', 'requires_one_of', 'cardinality', 'attribute_constraint'\n    source_product_id TEXT REFERENCES product(id),\n    target_product_id TEXT REFERENCES product(id),\n    target_group_id TEXT REFERENCES product_family(id),\n    min_cardinality INTEGER,\n    max_cardinality INTEGER,\n    condition_json TEXT,            -- For attribute constraints\n    error_message TEXT NOT NULL,\n    suggestion_message TEXT NOT NULL,\n    priority INTEGER NOT NULL DEFAULT 100,\n    active BOOLEAN NOT NULL DEFAULT 1,\n    created_at TEXT NOT NULL,\n    updated_at TEXT NOT NULL\n);\nCREATE INDEX idx_constraint_source ON constraint_rule(source_product_id) WHERE active = 1;\nCREATE INDEX idx_constraint_target ON constraint_rule(target_product_id) WHERE active = 1;\n```\n\n## Seed Data\n\nCreate meaningful constraints for demo products:\n- Enterprise Plan REQUIRES SSO Add-on\n- Basic Plan EXCLUDES Premium Support (basic customers get standard support only)\n- Plans family: CARDINALITY exactly 1 (must pick exactly one plan)\n- Support family: CARDINALITY at most 1 (at most one support tier)\n- If deployment=on-prem, REQUIRES Onboarding service\n\n## Dependencies\n\nDepends on bd-ce-1 (domain model) and bd-pc-2 (product schema must exist for foreign keys).", "labels": ["cpq", "constraints", "database", "migration"], "parent": "bd-ce"}
{"id": "bd-ce-3", "title": "Implement DatabaseConstraintEngine", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nNew implementation of the `ConstraintEngine` trait in `crates/core/src/cpq/constraints.rs` (or a new file) that:\n\n1. **Loads constraint rules from SQLite at construction** (or receives them as a Vec<ConstraintRule>)\n2. **Indexes rules by product ID** for O(1) lookup: `HashMap<ProductId, Vec<&ConstraintRule>>`\n3. **Evaluates all relevant rules** when `validate()` is called:\n   - For each product in the quote, find all rules referencing it\n   - Evaluate each rule against the full configuration\n   - Collect violations with user-friendly messages and suggestions\n4. **Preserves existing data hygiene checks** (empty quote, zero qty, etc.) as the first validation pass\n\n## Algorithm\n\n```\nfn validate(input: &ConstraintInput) -> ConstraintResult:\n    violations = run_data_hygiene_checks(input)  // existing logic\n    for line in input.quote_lines:\n        for rule in rules_index.get(line.product_id):\n            if !rule_is_satisfied(rule, input.quote_lines):\n                violations.push(rule.to_violation())\n    return ConstraintResult { valid: violations.is_empty(), violations }\n```\n\n## Testing Strategy\n\n- Test each constraint type independently with minimal quotes\n- Test constraint interactions (rule A + rule B both fire)\n- Test that existing data hygiene tests still pass (regression guard)\n- Test with seed data constraints (Enterprise + no SSO \u2192 violation)\n\n## Isomorphism\n\nFor quotes with no constraint rules loaded, output is identical to current DeterministicConstraintEngine. Constraint rules are additive \u2014 they can only add violations, never remove the existing hygiene checks. Same inputs \u2192 same or more violations.\n\n## Dependencies\n\nDepends on bd-ce-1 (domain model), bd-ce-2 (schema/data). Does not depend on SqlProductRepository \u2014 can use in-memory rule loading for tests.", "labels": ["cpq", "constraints", "engine"], "parent": "bd-ce"}
{"id": "bd-ce-4", "title": "Implement constraint propagation and valid-domain computation", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nAdd to the constraint engine:\n\n```rust\nfn valid_additions(&self, current_lines: &[QuoteLine], catalog: &Catalog) -> Vec<ValidAddition>\n\nstruct ValidAddition {\n    product_id: ProductId,\n    status: AdditionStatus,  // Available, Required, Excluded\n    reason: Option<String>,  // Why it's required/excluded\n}\n```\n\n## Algorithm: Forward Checking\n\n1. Start with all active products from the catalog\n2. For each product, evaluate what would happen if it were added to current_lines:\n   a. Would it violate an EXCLUDES rule? \u2192 mark as Excluded\n   b. Is it required by a REQUIRES rule from an existing product? \u2192 mark as Required\n   c. Would it violate a CARDINALITY constraint? \u2192 mark as Excluded\n   d. Otherwise \u2192 mark as Available\n3. Return the annotated list\n\n## Why This Is Critical for the Agent\n\nWithout this, the agent is blind. It can't say \"you need SSO\" or \"you can't add Premium Support with Basic Plan.\" With this, the agent can proactively suggest required products and prevent invalid configurations before the user asks.\n\n## Performance Consideration\n\nThis is called interactively (after each product addition in a Slack conversation). For catalogs of 20-200 SKUs (per PROJECT.md scope), the O(products \u00d7 rules) evaluation is trivially fast. No need for clever indexing \u2014 just iterate.\n\n## Dependencies\n\nDepends on bd-ce-3 (DatabaseConstraintEngine) and bd-pc-4 (enriched Catalog for product listing).", "labels": ["cpq", "constraints", "forward-checking"], "parent": "bd-ce"}
{"id": "bd-ce-5", "title": "Constraint suggestion generator for agent interaction", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nAdd resolution suggestions when constraint violations occur:\n\n```rust\nfn suggest_resolution(\n    &self,\n    violation: &ConstraintViolation,\n    current_lines: &[QuoteLine],\n    catalog: &Catalog,\n) -> Vec<ConstraintSuggestion>\n\npub struct ConstraintSuggestion {\n    pub action: SuggestionAction,  // Add, Remove, Replace\n    pub product_id: ProductId,\n    pub product_name: String,\n    pub explanation: String,\n}\n```\n\n## Resolution Logic by Constraint Type\n\n- **Requires violation** (\"Enterprise Plan requires SSO\"): Suggest Add(SSO)\n- **Excludes violation** (\"Basic Plan excludes Premium Support\"): Suggest Remove(Basic) or Remove(Premium Support) \u2014 let user choose\n- **Cardinality violation** (\"max 1 plan, you have 2\"): Suggest Remove for each excess product\n- **RequiresOneOf** (\"needs at least one from Support family\"): Suggest Add for each option in the family\n\n## Agent Integration\n\nThe agent formats these suggestions as Slack Block Kit buttons: \"I noticed Enterprise Plan requires SSO Add-on. [Add SSO Add-on] [Skip for now]\". The structured suggestions enable deterministic UI rendering \u2014 no LLM creativity in the suggestion itself, only in the conversational framing.\n\n## Dependencies\n\nDepends on bd-ce-4 (propagation logic) and bd-pc-4 (catalog for product names).", "labels": ["cpq", "constraints", "agent-integration"], "parent": "bd-ce"}
{"id": "bd-pe", "title": "EPIC: Pricing Engine - From Sum to Composable Pipeline", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## Problem\n\nThe pricing engine is `unit_price * quantity` \u2014 a trivial multiplication with no concept of price books, volume tiers, formulas, or discounts. PROJECT.md specifies: \"Database-driven pricing rules engine (price books, volume tiers, multi-dimensional pricing, formulas)\" \u2014 none of which exists.\n\nThis is the \"P\" in CPQ. Without it, Quotey is a quote form, not a pricing engine.\n\n## Target Architecture: Composable Pipeline\n\n```\nPriceBookResolver \u2192 VolumeTierCalculator \u2192 FormulaEvaluator \u2192 DiscountApplicator \u2192 TotalAggregator\n```\n\nEach stage:\n- Receives a `PricingContext` (running state: line prices, applied rules, trace steps)\n- Applies its logic deterministically\n- Emits zero or more `PricingTraceStep` entries\n- Returns the updated context\n- Is independently testable\n- Is a `PricingStage` trait implementation\n\n## Why the Pipeline Matters for CLO\n\nThe Closed-Loop Policy Optimizer needs to replay historical quotes against candidate rule changes. If pricing rules are hardcoded Rust code, there's nothing to swap. If they're database rows evaluated by a composable pipeline, the CLO can:\n1. Load historical quote inputs\n2. Swap one pricing rule\n3. Re-run the pipeline\n4. Compare PricingResults (same trace structure, different values)\n5. Quantify the impact of the proposed change\n\n## Pricing Trace as First-Class Output\n\nThe existing PricingTrace structure is architecturally sound \u2014 it just traces trivial operations. The pipeline architecture naturally produces rich traces:\n- \"PriceBook 'Enterprise 2026' applied: plan-enterprise @ $150.00/unit\"\n- \"Volume tier: 50 units in tier 50-100 @ $135.00/unit (10% volume discount)\"\n- \"Formula: premium-support = 18% \u00d7 $6,750.00 software license = $1,215.00\"\n- \"Discount: 'Annual commitment' 5% applied to subtotal = -$397.50\"\n\nThese traces are the audit trail that enterprise CPQ requires \u2014 \"explain exactly how every number was calculated.\"\n\n## Preserving Current Behavior\n\nThe existing `DeterministicPricingEngine` (sum of line totals) must be preserved as a baseline/fallback engine. Both engines implement the `PricingEngine` trait. The pipeline engine is the production engine; the baseline is for tests and as a sanity check.", "labels": ["cpq", "pricing", "foundation"]}
{"id": "bd-pe-1", "title": "Define pricing rule domain model (price books, tiers, formulas, discounts)", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nCreate pricing rule types in `crates/core/src/domain/` (new file `pricing_rules.rs`):\n\n- **PriceBook**: `{id, name, currency, customer_segment: Option<String>, effective_from: Option<DateTime>, effective_until: Option<DateTime>, priority: u32, active: bool}`\n- **PriceBookEntry**: `{id, price_book_id, product_id, unit_price: Decimal, min_quantity: Option<u32>, max_quantity: Option<u32>}`\n- **VolumeTier**: `{id, product_id, tier_type: TierType, bands: Vec<TierBand>}` where TierType is Step|Graduated\n- **TierBand**: `{min_qty: u32, max_qty: Option<u32>, unit_price: Decimal}`\n- **DiscountRule**: `{id, name, discount_type: DiscountType, value: Decimal, stackable: bool, stack_order: u32, condition_json: Option<String>, active: bool}` where DiscountType is Percentage|FixedAmount\n- **PricingFormula**: `{id, target_product_id: ProductId, expression: String, depends_on: Vec<ProductId>}`\n\n## Expression Language for Formulas\n\nSimple, deterministic, auditable:\n- Literals: `100`, `0.18`\n- References: `line(\"plan-pro\").subtotal`, `quote.subtotal`\n- Operators: `+`, `-`, `*`, `/`, `%` (percentage-of)\n- Functions: `min(a, b)`, `max(a, b)`, `round(a, decimals)`\n- Conditional: `if(condition, then, else)`\n\nNo loops, no user-defined functions, no side effects. The expression is parsed at rule creation time (not evaluation time) \u2014 syntax errors are caught early.\n\n## All Decimal Arithmetic\n\nAll monetary values use `rust_decimal::Decimal`. No f64 anywhere in pricing. This is non-negotiable for CPQ \u2014 floating point introduces rounding errors that accumulate across line items.\n\n## Dependencies\n\nDepends on bd-pc-1 (ProductId type). No DB dependency \u2014 pure domain types.", "labels": ["cpq", "pricing", "domain-model"], "parent": "bd-pe"}
{"id": "bd-pe-2", "title": "Create pricing rules SQLite schema", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nMigration creating tables for all pricing rule types:\n\n```sql\nCREATE TABLE price_book (...);\nCREATE TABLE price_book_entry (...);\nCREATE TABLE volume_tier (...);\nCREATE TABLE tier_band (...);\nCREATE TABLE discount_rule (...);\nCREATE TABLE pricing_formula (...);\n```\n\nInclude indexes on (product_id) for price_book_entry, volume_tier, pricing_formula. Include index on (price_book_id, product_id) for entry lookups.\n\n## Seed Data\n\n- Default price book with entries for all demo products\n- Volume tiers for Enterprise Plan: 1-9 seats full price, 10-49 seats 10% off, 50+ seats 20% off (step pricing)\n- Formula: \"Premium Support = 18% of total plan license value\"\n- Discount rules: \"Annual commitment\" 5% off, \"Multi-year\" 10% off (stackable, ordered)\n\n## Dependencies\n\nDepends on bd-pe-1 (domain model alignment) and bd-pc-2 (product tables for foreign keys).", "labels": ["cpq", "pricing", "database", "migration"], "parent": "bd-pe"}
{"id": "bd-pe-3", "title": "Implement PricingContext, PricingStage trait, and pipeline executor", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nDefine the pipeline abstraction in `crates/core/src/cpq/pricing.rs`:\n\n```rust\npub struct PricingContext {\n    pub quote: Quote,\n    pub currency: String,\n    pub line_results: HashMap<ProductId, LinePricingResult>,\n    pub subtotal: Decimal,\n    pub discount_total: Decimal,\n    pub tax_total: Decimal,\n    pub total: Decimal,\n    pub trace_steps: Vec<PricingTraceStep>,\n    pub metadata: HashMap<String, String>,  // Customer segment, contract info, etc.\n}\n\npub struct LinePricingResult {\n    pub product_id: ProductId,\n    pub quantity: u32,\n    pub unit_price: Decimal,\n    pub line_total: Decimal,\n    pub applied_tier: Option<String>,\n    pub applied_discounts: Vec<String>,\n}\n\npub trait PricingStage: Send + Sync {\n    fn name(&self) -> &str;\n    fn apply(&self, ctx: &mut PricingContext) -> Result<(), PricingStageError>;\n}\n```\n\nThe pipeline executor:\n```rust\npub struct PricingPipeline {\n    stages: Vec<Box<dyn PricingStage>>,\n}\n\nimpl PricingPipeline {\n    pub fn execute(&self, quote: &Quote, currency: &str) -> PricingResult {\n        let mut ctx = PricingContext::new(quote, currency);\n        for stage in &self.stages {\n            stage.apply(&mut ctx)?;\n        }\n        ctx.into_result()\n    }\n}\n```\n\n## Isomorphism with Current Engine\n\n`PricingContext::into_result()` produces the same `PricingResult` struct. A pipeline with only a `BaseLinePricingStage` (that just sums unit_price \u00d7 quantity) produces identical output to the current `DeterministicPricingEngine`. This is the regression guard.\n\n## Dependencies\n\nDepends on bd-pe-1 (pricing rule types for stage implementations).", "labels": ["cpq", "pricing", "pipeline", "architecture"], "parent": "bd-pe"}
{"id": "bd-pe-4", "title": "Implement PriceBookResolver stage", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nFirst stage in the pricing pipeline. Resolves the applicable price book and sets base unit prices.\n\n## Algorithm\n\n1. Load price books ordered by priority (highest priority first)\n2. Filter by: currency matches, customer segment matches (if specified), current date within effective range (if specified), active=true\n3. For each quote line:\n   a. Find the first matching PriceBookEntry in the highest-priority applicable book\n   b. If found, set line's unit_price from the entry (overriding the quote line's unit_price)\n   c. If not found in any book, keep the quote line's original unit_price (graceful fallback)\n4. Emit trace step per line: \"PriceBook '{name}' resolved: {product} @ {price}/unit\"\n\n## Why Graceful Fallback\n\nSales reps may add products not yet in any price book (new products, custom items). The fallback ensures the pipeline doesn't break \u2014 it just uses the manually-entered price and traces the decision.\n\n## Dependencies\n\nDepends on bd-pe-3 (PricingStage trait) and bd-pe-2 (price book schema/data).", "labels": ["cpq", "pricing", "price-books"], "parent": "bd-pe"}
{"id": "bd-pe-5", "title": "Implement VolumeTierCalculator stage", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nSecond stage. Applies volume tier pricing to lines that have tier definitions.\n\n## Two Pricing Models\n\n### Step Pricing\nAll units at the tier price. Example:\n- Tier 1: 1-9 units @ $150/unit\n- Tier 2: 10-49 units @ $135/unit\n- Tier 3: 50+ units @ $120/unit\n- If buying 30 units: all 30 @ $135/unit = $4,050\n\n### Graduated Pricing\nEach tranche at its own price. Example (same tiers):\n- If buying 30 units: 9 @ $150 + 21 @ $135 = $1,350 + $2,835 = $4,185\n\n## Algorithm\n\nFor each line in quote:\n1. Look up VolumeTier for this product\n2. If no tier definition exists, skip (line keeps current price)\n3. If Step: find the tier where quantity falls, set unit_price\n4. If Graduated: split quantity across tier bands, compute weighted total, set effective unit_price = total / quantity\n5. Emit trace step: \"Volume tier ({step|graduated}): {qty} units, effective @ {price}/unit\"\n6. For graduated, emit sub-steps showing each tranche\n\n## Edge Cases\n\n- Quantity exactly on tier boundary: belongs to the lower tier (inclusive lower bound)\n- Quantity exceeding all defined tiers: use last tier's price (highest tier is unbounded)\n- Zero or negative quantity: skip (constraint engine should have caught this)\n\n## Dependencies\n\nDepends on bd-pe-3 (PricingStage trait) and bd-pe-2 (volume tier data).", "labels": ["cpq", "pricing", "volume-tiers"], "parent": "bd-pe"}
{"id": "bd-pe-6", "title": "Implement FormulaEvaluator stage", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nThird stage. Evaluates pricing formulas \u2014 derived pricing where one line's price depends on other lines.\n\n## Algorithm\n\n1. Load all PricingFormula rules\n2. Build dependency graph: formula \u2192 depends_on products\n3. Topological sort (detect cycles \u2014 reject with error if found)\n4. Evaluate each formula in topological order:\n   a. Resolve references: `line(\"plan-enterprise\").subtotal` \u2192 look up in PricingContext.line_results\n   b. Evaluate expression using Decimal arithmetic\n   c. Set the target line's unit_price or total from the formula result\n5. Emit trace step: \"Formula: {target} = {expression} = {result}\"\n\n## Expression Evaluator\n\nSimple recursive descent parser for the expression language defined in bd-pe-1. Uses a stack-based evaluator with Decimal arithmetic throughout. No floating point. The evaluator is deterministic: same expression + same context \u2192 same result.\n\n## Cycle Detection\n\nCycles must be detected at formula creation time, not evaluation time. The formula table should have a constraint check, but the evaluator also validates at runtime as a safety net.\n\n## Dependencies\n\nDepends on bd-pe-3 (PricingStage trait), bd-pe-2 (formula data), and implicitly on PriceBookResolver and VolumeTierCalculator having run first (formulas reference resolved prices).", "labels": ["cpq", "pricing", "formulas"], "parent": "bd-pe"}
{"id": "bd-pe-7", "title": "Implement DiscountApplicator stage", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nFourth stage. Applies discount rules to the priced quote.\n\n## Discount Types\n\n- **Percentage**: X% off a target (line or subtotal). Example: \"10% volume discount on plan-enterprise\"\n- **FixedAmount**: Flat $X reduction. Example: \"$500 loyalty credit\"\n\n## Stacking\n\nDiscounts have a `stack_order` and a `stackable` flag:\n- Ordered by stack_order ascending\n- **Compound stacking** (default): Each discount applies to the already-discounted amount. 10% then 5% = 0.95 \u00d7 0.90 \u00d7 original = 14.5% total\n- **Additive stacking**: Discounts apply to the original amount and sum. 10% + 5% = 15% total\n\nThe stacking behavior is a system-level configuration, not per-discount. Enterprise CPQ systems typically use compound stacking.\n\n## Algorithm\n\n1. Load active discount rules, ordered by stack_order\n2. For each discount rule:\n   a. Evaluate condition_json against quote context (customer segment, deal size, etc.)\n   b. If condition matches, apply discount to target (line or subtotal)\n   c. Record the discount amount in discount_total\n   d. Emit trace step: \"Discount '{name}': {type} {value} applied = -{amount}\"\n3. Update PricingContext.discount_total and PricingContext.total\n\n## Dependencies\n\nDepends on bd-pe-3 (PricingStage trait) and bd-pe-2 (discount rule data).", "labels": ["cpq", "pricing", "discounts"], "parent": "bd-pe"}
{"id": "bd-pe-8", "title": "Compose PipelinePricingEngine and integration test", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nImplementation of PricingEngine trait that composes all stages:\n\n```rust\nimpl PricingEngine for PipelinePricingEngine {\n    fn price(&self, quote: &Quote, currency: &str) -> PricingResult {\n        self.pipeline.execute(quote, currency)\n    }\n}\n```\n\n## Construction\n\n```rust\nlet pipeline = PricingPipeline::new(vec![\n    Box::new(PriceBookResolver::new(price_books, entries)),\n    Box::new(VolumeTierCalculator::new(tiers)),\n    Box::new(FormulaEvaluator::new(formulas)),\n    Box::new(DiscountApplicator::new(rules)),\n    Box::new(TotalAggregator),  // final summation\n]);\nlet engine = PipelinePricingEngine::new(pipeline);\n```\n\n## Critical Regression Test\n\nThe DeterministicPricingEngine (baseline: sum of unit_price \u00d7 quantity) must produce identical results to PipelinePricingEngine when:\n- No price books loaded (fallback to original prices)\n- No volume tiers\n- No formulas\n- No discounts\n\nThis proves the pipeline is a strict superset of the baseline engine.\n\n## Integration Test with Seed Data\n\nUsing the seed data from bd-pe-2, run the pipeline and verify:\n- Price book resolves correct prices\n- Volume tiers apply correctly for 10+ and 50+ quantities\n- Support formula computes 18% of license total\n- Discounts apply and stack correctly\n- Trace contains all expected steps\n- Total matches hand-calculated expected value\n\n## Dependencies\n\nDepends on bd-pe-3 (pipeline abstraction), bd-pe-4 (PriceBookResolver), bd-pe-5 (VolumeTierCalculator). Optionally bd-pe-6 and bd-pe-7 if those are complete; otherwise test with available stages.", "labels": ["cpq", "pricing", "integration"], "parent": "bd-pe"}
{"id": "bd-po", "title": "EPIC: Policy Engine - Hardcoded Thresholds to Database-Driven Rules", "status": "open", "priority": 1, "issue_type": "epic", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## Problem\n\nThe policy engine has three hardcoded thresholds in Rust:\n- Discount > 30% \u2192 requires VP Finance approval\n- Discount > 20% \u2192 requires Sales Manager approval\n- Margin < 10% \u2192 requires Finance approval\n\nPROJECT.md specifies: \"Configuration rules and pricing policies stored in SQLite, manageable via CLI without recompilation.\" The hardcoded thresholds directly violate this.\n\n## Why This Must Change\n\n1. **Enterprise CPQ reality**: Policies change weekly. New approval thresholds, new approver roles, new conditions. Recompiling and redeploying for each policy change is unacceptable.\n2. **CLO integration**: The Closed-Loop Policy Optimizer needs to propose candidate policy changes and replay them. If policies are Rust constants, there's nothing to optimize.\n3. **Multi-segment policies**: Different customer segments may have different thresholds. Enterprise customers might get 25% discount authority at sales manager level, while SMB gets only 15%. Hardcoded thresholds can't express this.\n4. **Audit trail**: When a quote is approved under policy version N, and policies later change to version N+1, the audit trail must record which version was in effect. Hardcoded thresholds have no version concept.\n\n## Scope\n\n1. Policy rule domain model with conditions, thresholds, and versioning\n2. SQLite schema with versioned policy rules\n3. DatabasePolicyEngine that loads and evaluates rules from SQLite\n4. Replay support for CLO integration", "labels": ["cpq", "policy", "foundation"]}
{"id": "bd-po-1", "title": "Define policy rule domain model with conditions and versioning", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nIn `crates/core/src/domain/` (new file `policy_rules.rs`):\n\n```rust\npub struct PolicyRule {\n    pub id: PolicyRuleId,\n    pub policy_type: PolicyType,       // DiscountCap, MarginFloor, DealSizeThreshold\n    pub condition: Option<PolicyCondition>,  // When this rule applies\n    pub field: PolicyField,            // Which field to evaluate\n    pub operator: ComparisonOperator,  // Gt, Gte, Lt, Lte\n    pub threshold: Decimal,            // The threshold value\n    pub required_approver_role: String, // Who must approve if violated\n    pub severity: PolicySeverity,      // Warning, RequiresApproval, Blocked\n    pub priority: u32,                 // Evaluation order\n    pub active: bool,\n    pub version_id: PolicyVersionId,\n}\n\npub struct PolicyVersion {\n    pub id: PolicyVersionId,\n    pub version_number: u32,\n    pub effective_at: DateTime<Utc>,\n    pub description: String,\n    pub created_by: String,\n}\n\npub struct PolicyCondition {\n    pub field: String,           // e.g., \"customer_segment\"\n    pub operator: ComparisonOperator,\n    pub value: String,           // e.g., \"enterprise\"\n}\n```\n\n## Version Semantics\n\n- Each PolicyRule belongs to exactly one PolicyVersion\n- At any time, exactly one version is \"active\" (the latest effective_at <= now)\n- Creating new rules creates a new version \u2014 old rules in old versions are immutable\n- The CLO proposes a candidate version, replays against it, and if approved, it becomes the new active version\n\n## Dependencies\n\nNone \u2014 pure domain types in core crate.", "labels": ["cpq", "policy", "domain-model"], "parent": "bd-po"}
{"id": "bd-po-2", "title": "Create policy rules SQLite schema with versioning", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nMigration creating versioned policy rule tables.\n\n## Seed Data: Current Hardcoded Rules as Database Entries\n\nThe seed data must reproduce the exact same decisions as the current hardcoded engine:\n- Version 1 (initial), effective_at = epoch\n- Rule: discount_cap, threshold=30%, operator=Gt, approver=vp_finance, priority=1\n- Rule: discount_cap, threshold=20%, operator=Gt, approver=sales_manager, priority=2\n- Rule: margin_floor, threshold=10%, operator=Lt, approver=finance, priority=1\n\n## Backwards Compatibility Test\n\nAfter seeding, running the DatabasePolicyEngine with these rules against the same PolicyInput as the existing tests must produce identical PolicyDecision output. This is the critical migration verification.\n\n## Dependencies\n\nDepends on bd-po-1 (domain model for column alignment).", "labels": ["cpq", "policy", "database", "migration"], "parent": "bd-po"}
{"id": "bd-po-3", "title": "Implement DatabasePolicyEngine", "status": "open", "priority": 1, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nNew implementation of `PolicyEngine` trait that loads and evaluates rules from data.\n\n## Algorithm\n\n1. At construction, load the active PolicyVersion and its rules\n2. `evaluate(input: &PolicyInput) -> PolicyDecision`:\n   a. Filter rules by condition: for each rule, if condition is Some, evaluate condition against quote context. If condition doesn't match, skip rule.\n   b. Evaluate matching rules: compare input field against threshold using operator\n   c. Collect violations: each violated rule produces a PolicyViolation with policy_id, reason, required_approval\n   d. Determine approval status: if any violations exist, approval_required=true, pick highest-authority approver\n3. Record the policy_version_id in the response for audit trail\n\n## Critical: Exact Equivalence Test\n\nWrite a test that runs both DeterministicPolicyEngine (hardcoded) and DatabasePolicyEngine (seed data) against the same set of PolicyInput values and asserts identical PolicyDecision output for all cases:\n- Normal quote (no violations in either engine)\n- High discount (both engines trigger discount_cap)\n- Low margin (both engines trigger margin_floor)\n- Both violations simultaneously\n\nThis proves the migration is lossless.\n\n## Dependencies\n\nDepends on bd-po-1 (domain model) and bd-po-2 (schema + seed data).", "labels": ["cpq", "policy", "engine"], "parent": "bd-po"}
{"id": "bd-po-4", "title": "Policy replay support for CLO integration", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nAdd replay capability for the CLO (Closed-Loop Policy Optimizer):\n\n```rust\nimpl DatabasePolicyEngine {\n    /// Evaluate using candidate rules instead of active version\n    pub fn replay_with_candidate(\n        &self,\n        input: &PolicyInput,\n        candidate_rules: &[PolicyRule],\n    ) -> PolicyDecision { ... }\n\n    /// Compare baseline (active version) vs candidate evaluation\n    pub fn compare_replay(\n        &self,\n        input: &PolicyInput,\n        candidate_rules: &[PolicyRule],\n    ) -> ReplayComparison { ... }\n}\n\npub struct ReplayComparison {\n    pub baseline: PolicyDecision,\n    pub candidate: PolicyDecision,\n    pub approval_required_changed: bool,\n    pub new_violations: Vec<PolicyViolation>,\n    pub cleared_violations: Vec<PolicyViolation>,\n}\n```\n\n## Why\n\nThe CLO spec (W2_CLO) describes: \"replay-gated, human-approved policy optimization.\" The replay mechanism is: given a historical quote and a proposed policy change, what would the decision have been? The `compare_replay` output feeds the CLO's blast-radius scoring.\n\n## Dependencies\n\nDepends on bd-po-3 (DatabasePolicyEngine). Connects to existing CLO infrastructure in `crates/core/src/policy/optimizer.rs`.", "labels": ["cpq", "policy", "clo", "replay"], "parent": "bd-po"}
{"id": "bd-ac", "title": "EPIC: Agent Conversation Layer - Keyword Matching to Structured Slot-Filling", "status": "open", "priority": 2, "issue_type": "epic", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## Problem\n\nThe agent runtime in `crates/agent/src/runtime.rs` classifies intent using `text.to_ascii_lowercase().contains(\"price override\")`. This keyword-matching approach:\n- Can't extract structured data (it detects \"price override\" but can't extract WHICH price or WHICH product)\n- Can't handle synonyms or paraphrasing (\"change the cost\" vs \"update the price\")\n- Can't track conversation state (which fields have been gathered across multiple turns)\n- Can't generate meaningful clarification questions\n\n## Target Architecture: Slot-Filling State Machine\n\nThe conversation layer should have three cleanly separated concerns:\n\n1. **Slot Schema** (definition): What fields does this flow type need? What types are they? Which are required?\n2. **LLM Extraction** (translation): Convert raw NL text into structured slot deltas. The LLM is a translator, not a decision-maker.\n3. **Slot Machine** (tracking): Track which slots are filled, which are missing, when to advance the flow. Deterministic \u2014 given same (state, delta), produces same new state.\n\n## Interaction Model\n\n```\nUser message in Slack\n  \u2192 LLM extracts structured fields with confidence scores\n    \u2192 Slot machine validates against schema\n      \u2192 If all required slots filled \u2192 FlowEvent::RequiredFieldsCollected\n      \u2192 If slots missing \u2192 Generate targeted prompt for next missing field\n      \u2192 If extraction ambiguous \u2192 Generate clarification question\n```\n\n## Safety Principle\n\nThe LLM produces the slot delta. The slot machine decides what happens next. The flow engine governs the lifecycle. This three-layer separation ensures the LLM never decides prices, policies, or workflow \u2014 it only translates natural language into structured data.\n\n## Dependencies\n\nThe slot machine connects to: FlowContext.missing_required_fields (flow engine), Catalog (product matching), ConstraintEngine.valid_additions (for product suggestions).", "labels": ["agent", "conversation", "slot-filling"]}
{"id": "bd-ac-1", "title": "Define slot-filling state machine types and transitions", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nIn `crates/agent/src/` (new file `slots.rs`):\n\n```rust\npub struct SlotSchema {\n    pub flow_type: FlowType,\n    pub slots: Vec<SlotDefinition>,\n}\n\npub struct SlotDefinition {\n    pub name: String,                 // \"customer_name\", \"billing_country\", \"term_months\"\n    pub slot_type: SlotType,          // String, Number, Date, ProductId, Enum(Vec<String>)\n    pub required: bool,\n    pub confidence_threshold: f64,    // Minimum confidence to auto-accept (e.g., 0.8)\n    pub prompt_template: String,      // \"What country should I bill to?\"\n}\n\npub struct SlotState {\n    pub filled: HashMap<String, SlotValue>,\n    pub confidence: HashMap<String, f64>,\n    pub pending_clarification: Option<String>,  // Slot awaiting user confirmation\n}\n\npub struct SlotDelta {\n    pub extracted: Vec<(String, SlotValue, f64)>,  // (slot_name, value, confidence)\n    pub raw_text: String,\n}\n\npub enum SlotValue {\n    Text(String),\n    Number(Decimal),\n    Date(NaiveDate),\n    ProductRef(ProductId),\n    Enum(String),\n}\n```\n\n## State Transitions\n\n```\napply_delta(state: &SlotState, delta: &SlotDelta, schema: &SlotSchema) -> SlotState\n```\n\nFor each extracted (name, value, confidence):\n1. If slot doesn't exist in schema \u2192 ignore (don't crash on unexpected extractions)\n2. If confidence >= threshold \u2192 fill the slot\n3. If confidence < threshold \u2192 set pending_clarification to ask user to confirm\n4. If slot type doesn't match extracted value \u2192 ignore with warning\n\n## Determinism\n\nThe slot machine is pure: no side effects, no randomness, no LLM calls. Given the same (state, delta, schema), it always produces the same output.\n\n## Dependencies\n\nNone \u2014 pure domain types and logic.", "labels": ["agent", "slot-filling", "state-machine"], "parent": "bd-ac"}
{"id": "bd-ac-2", "title": "Implement structured extraction pipeline", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nPipeline: raw_text \u2192 LLM extraction \u2192 schema validation \u2192 slot delta.\n\n## LLM Extraction\n\nCall the existing `LlmProvider` trait with a structured prompt:\n```\nYou are extracting structured fields from a sales conversation.\n\nCurrent empty fields:\n- billing_country (country code, e.g., \"US\", \"DE\", \"JP\")\n- term_months (integer, typically 12, 24, or 36)\n- plan_tier (one of: basic, pro, enterprise)\n\nUser message: \"We need the enterprise tier for 2 years, billing from Germany\"\n\nExtract as JSON:\n{\"billing_country\": \"DE\", \"term_months\": 24, \"plan_tier\": \"enterprise\"}\n```\n\n## Fallback Chain\n\n1. Try LLM extraction (primary)\n2. If LLM fails or returns empty, try regex patterns for common formats:\n   - ISO dates: `\\d{4}-\\d{2}-\\d{2}`\n   - Currency: `\\$[\\d,]+\\.?\\d*`\n   - Quantities: `(\\d+)\\s*(seats?|users?|licenses?)`\n   - Product SKUs: exact match against catalog SKU list\n3. If both fail, report no extraction (prompt user for explicit input)\n\n## Dependencies\n\nDepends on bd-ac-1 (SlotDelta type). Uses existing LlmProvider trait from `crates/agent/src/llm.rs`.", "labels": ["agent", "extraction", "llm"], "parent": "bd-ac"}
{"id": "bd-ac-3", "title": "Connect slot machine to flow engine required fields", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nBridge the slot state to `FlowContext.missing_required_fields`:\n\n```rust\npub fn slot_state_to_flow_context(state: &SlotState, schema: &SlotSchema) -> FlowContext {\n    let missing = schema.slots.iter()\n        .filter(|def| def.required && !state.filled.contains_key(&def.name))\n        .map(|def| def.name.clone())\n        .collect();\n    FlowContext { missing_required_fields: missing }\n}\n```\n\nWhen all required slots are filled \u2192 emit `FlowEvent::RequiredFieldsCollected`\nWhen slots are missing \u2192 the flow engine returns `FlowAction::PromptForMissingFields`\nThe agent formats the prompt using the SlotDefinition.prompt_template for the first missing slot.\n\n## Integration Point\n\nThis connects the conversation layer to the deterministic flow engine. The agent's behavior is ultimately governed by the flow state machine, not the LLM:\n1. LLM extracts fields \u2192 slot machine updates \u2192 flow context changes \u2192 flow engine decides next action\n2. The LLM never directly triggers flow transitions \u2014 only the slot machine + flow engine do\n\n## Dependencies\n\nDepends on bd-ac-1 (slot types) and the existing flow engine in `crates/core/src/flows/`.", "labels": ["agent", "flow-engine", "integration"], "parent": "bd-ac"}
{"id": "bd-si", "title": "EPIC: Similarity Index - Brute Force to LSH-Accelerated Lookup", "status": "open", "priority": 3, "issue_type": "epic", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## Problem\n\n`SimilarityEngine::find_similar` in `crates/core/src/dna/mod.rs` does O(n) brute-force scan over all candidates, computing Hamming distance for each. Recent optimization improved from full O(n log n) sort to O(n + k log k) partial sort, but the O(n) scan remains.\n\nFor the current test (10k candidates), this completes in <100ms. But at enterprise scale (50k-100k historical deals), and for interactive use (precedent lookup during a Slack conversation), this becomes a latency concern.\n\n## Why LSH Is the Right Approach\n\nThe 128-bit SimHash fingerprints used by the DNA module naturally support Locality-Sensitive Hashing (LSH). SimHash has the property that similar inputs produce similar hashes \u2014 specifically, the probability that two fingerprints collide in a random bit position equals their cosine similarity.\n\nLSH exploits this by partitioning the hash into bands. Two fingerprints that collide in any band are candidates for exact comparison. This reduces the scan from O(n) to O(candidates) where candidates << n.\n\n## Parameters\n\nWith b=8 bands of r=16 bits each (128 bits total):\n- P(collision | similarity=0.9) \u2248 73% (high recall for similar deals)\n- P(collision | similarity=0.5) \u2248 0.0005% (very few false candidates)\n- Expected candidates for n=10k, similarity\u22650.8: ~100-200 (vs 10,000 brute-force)\n\n## Scope\n\n1. In-memory LSH index implementation\n2. SQLite storage schema for persistent buckets\n3. Integration with SimilarityEngine (LSH as optional accelerator)\n4. Benchmark: brute-force vs LSH for various candidate set sizes", "labels": ["dna", "similarity", "performance", "lsh"]}
{"id": "bd-si-1", "title": "Implement LSH band partitioning for SimHash fingerprints", "status": "open", "priority": 3, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nIn `crates/core/src/dna/mod.rs` (or new file `crates/core/src/dna/lsh.rs`):\n\n```rust\npub struct LshIndex {\n    bands: usize,         // Number of bands (b)\n    rows_per_band: usize, // Bits per band (r)\n    buckets: Vec<HashMap<u64, Vec<String>>>,  // band_index \u2192 band_hash \u2192 quote_ids\n}\n\nimpl LshIndex {\n    pub fn new(bands: usize, rows_per_band: usize) -> Self;\n\n    /// Insert a fingerprint into all band buckets\n    pub fn insert(&mut self, fingerprint: &ConfigurationFingerprint, quote_id: &str);\n\n    /// Query: return candidate quote_ids that collide in any band\n    pub fn query(&self, fingerprint: &ConfigurationFingerprint) -> HashSet<String>;\n\n    /// Compute band hash for a specific band from a fingerprint\n    fn band_hash(fingerprint: &ConfigurationFingerprint, band_index: usize, rows_per_band: usize) -> u64;\n}\n```\n\n## Band Hash Computation\n\nFor band i with r rows: extract bits [i*r .. (i+1)*r] from the 128-bit fingerprint, pack into a u64 (since r=16 fits in u64). Use a fast hash (FxHash or direct bit packing) for the bucket key.\n\n## Testing\n\n- Insert two identical fingerprints: query returns both in all bands\n- Insert two very similar fingerprints (Hamming distance 5): query returns both (high probability)\n- Insert two very different fingerprints (Hamming distance 60): query returns neither (high probability)\n- Insert 10k fingerprints: query time < 1ms\n\n## Dependencies\n\nNone \u2014 uses existing ConfigurationFingerprint type.", "labels": ["dna", "lsh", "data-structure"], "parent": "bd-si"}
{"id": "bd-si-2", "title": "Create LSH bucket SQLite schema", "status": "open", "priority": 3, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nMigration for persistent LSH buckets:\n\n```sql\nCREATE TABLE dna_lsh_bucket (\n    band_index INTEGER NOT NULL,\n    band_hash TEXT NOT NULL,\n    quote_id TEXT NOT NULL,\n    fingerprint_hash TEXT NOT NULL,  -- For verification\n    created_at TEXT NOT NULL,\n    PRIMARY KEY (band_index, band_hash, quote_id)\n);\nCREATE INDEX idx_lsh_lookup ON dna_lsh_bucket(band_index, band_hash);\n```\n\n## Lifecycle\n\n- On quote finalization (fingerprint generated): insert into all bands\n- On quote revision (fingerprint updated): delete old entries, insert new ones\n- The DealDnaLifecycleService already has hooks for these events (on_quote_closed, on_quote_reopened_or_modified)\n\n## Dependencies\n\nDepends on bd-si-1 (in-memory LSH for the band_hash computation logic).", "labels": ["dna", "lsh", "database", "migration"], "parent": "bd-si"}
{"id": "bd-si-3", "title": "Integrate LSH index with SimilarityEngine", "status": "open", "priority": 3, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nMake LSH an optional accelerator in SimilarityEngine:\n\n```rust\npub struct SimilarityEngine {\n    min_similarity: f32,\n    candidates: Vec<SimilarityCandidate>,\n    lsh_index: Option<LshIndex>,  // NEW: optional accelerator\n}\n\nimpl SimilarityEngine {\n    pub fn with_lsh_index(mut self, index: LshIndex) -> Self;\n\n    pub fn find_similar(&self, fingerprint: &ConfigurationFingerprint, limit: usize) -> Vec<SimilarDeal> {\n        let candidates_to_evaluate = match &self.lsh_index {\n            Some(index) => {\n                let candidate_ids = index.query(fingerprint);\n                self.candidates.iter()\n                    .filter(|c| candidate_ids.contains(&c.outcome.quote_id))\n                    .collect()\n            }\n            None => self.candidates.iter().collect(),  // brute force fallback\n        };\n        // ... rest of existing logic (Hamming distance, filter, partial sort)\n    }\n}\n```\n\n## Isomorphism Guarantee\n\nThe LSH index only filters WHICH candidates are evaluated \u2014 it doesn't change the ranking logic, similarity computation, or output format. For any candidate that LSH includes, the exact Hamming distance is still computed. LSH is a probabilistic pre-filter: it may miss some candidates (false negatives), but never produces wrong results for candidates it does include.\n\nThe brute-force fallback (no LSH index) guarantees identical output to the current implementation. When LSH is enabled, results are identical EXCEPT for potential false negatives near the similarity threshold (candidates with similarity very close to min_similarity may occasionally be missed).\n\n## Benchmark Test\n\nAdd a benchmark that compares:\n- Brute force on 10k candidates: measure latency\n- LSH-accelerated on 10k candidates: measure latency\n- Verify: >95% result overlap (recall) with brute force\n\n## Dependencies\n\nDepends on bd-si-1 (LshIndex implementation).", "labels": ["dna", "lsh", "integration"], "parent": "bd-si"}
{"id": "bd-sw", "title": "EPIC: Server Wiring - Components to Running System", "status": "open", "priority": 2, "issue_type": "epic", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## Problem\n\nAll CPQ components (flow engine, constraint engine, pricing engine, policy engine, repositories, agent runtime) are independently tested and working. But they've never been composed into a running system:\n- SqlProductRepository returns errors (\"product catalog tables are not present\")\n- The server bootstrap in `crates/server/src/bootstrap.rs` doesn't wire engines to repositories\n- There are no integration tests that exercise the full quote lifecycle\n- The Slack socket handler can't process real quotes because the CPQ pipeline isn't wired\n\n## What \"Wiring\" Means\n\nDependency injection at the composition root:\n1. Create DbPool from config\n2. Run pending migrations\n3. Load product catalog from DB into in-memory Catalog\n4. Construct constraint/pricing/policy engines with DB-backed rule loading\n5. Construct CpqRuntime with all three engines\n6. Construct FlowEngine with NetNewFlow\n7. Construct AgentRuntime with all dependencies\n8. Wire Slack handlers to agent runtime\n9. Start health check endpoint\n10. Enter main event loop\n\n## This Is the \"Capstone\"\n\nEvery other epic in this set produces independently correct components. This epic composes them into a system. It's where integration bugs surface \u2014 mismatched types, missing data, incorrect initialization order, transaction boundaries.\n\n## Dependencies\n\nDepends on: bd-pc (product catalog), bd-ce (constraints), bd-pe (pricing), bd-po (policy). Can start with available engines and grow as more engines are completed.", "labels": ["server", "integration", "wiring"]}
{"id": "bd-sw-1", "title": "Implement service composition at bootstrap", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nIn `crates/server/src/bootstrap.rs`, create a `ServiceContainer` that holds all wired services:\n\n```rust\npub struct ServiceContainer {\n    pub pool: DbPool,\n    pub catalog: Catalog,\n    pub cpq_runtime: DeterministicCpqRuntime<DatabaseConstraintEngine, PipelinePricingEngine, DatabasePolicyEngine>,\n    pub flow_engine: FlowEngine<NetNewFlow>,\n    pub agent_runtime: AgentRuntime,\n    pub audit_sink: Box<dyn AuditSink>,\n}\n\nimpl ServiceContainer {\n    pub async fn from_config(config: &QuoteyConfig) -> Result<Self> {\n        let pool = connect_with_settings(&config.database.url, ...).await?;\n        run_pending(&pool).await?;\n\n        let products = SqlProductRepository::new(pool.clone()).list_all().await?;\n        let catalog = Catalog::new(products);\n\n        let constraint_engine = DatabaseConstraintEngine::new(/* rules from DB */);\n        let pricing_engine = PipelinePricingEngine::new(/* stages from DB */);\n        let policy_engine = DatabasePolicyEngine::new(/* rules from DB */);\n\n        let cpq_runtime = DeterministicCpqRuntime::new(constraint_engine, pricing_engine, policy_engine);\n        // ... etc\n    }\n}\n```\n\n## Incremental Approach\n\nStart with what's available NOW:\n- Phase 1: Wire with existing DeterministicConstraintEngine, DeterministicPricingEngine, DeterministicPolicyEngine\n- Phase 2: Swap in database-backed engines as epics complete\n\n## Dependencies\n\nDepends on at least bd-pc-3 (SqlProductRepository) to replace the stub. Can use existing deterministic engines as placeholders for constraint/pricing/policy.", "labels": ["server", "bootstrap", "dependency-injection"], "parent": "bd-sw"}
{"id": "bd-sw-2", "title": "Integration test for full quote lifecycle", "status": "open", "priority": 2, "issue_type": "task", "created_at": "2026-02-26T11:43:27Z", "created_by": "amp-perf-analysis", "updated_at": "2026-02-26T11:43:27Z", "description": "## What\n\nEnd-to-end test that exercises the complete quote lifecycle through the ServiceContainer:\n\n```rust\n#[tokio::test]\nasync fn full_quote_lifecycle_happy_path() {\n    let container = ServiceContainer::test_container().await;\n\n    // 1. Create quote\n    let quote = Quote { id: QuoteId(\"Q-E2E-001\"), status: Draft, lines: vec![...] };\n    container.quote_repo.save(quote.clone()).await;\n\n    // 2. Validate constraints\n    let constraints = container.cpq_runtime.evaluate_quote(...);\n    assert!(constraints.constraints.valid);\n\n    // 3. Price quote\n    assert!(constraints.pricing.total > Decimal::ZERO);\n\n    // 4. Check policy\n    // ... assert approval_required based on discount level\n\n    // 5. Advance flow\n    let transition = container.flow_engine.apply(&FlowState::Draft, &FlowEvent::RequiredFieldsCollected, ...);\n    assert_eq!(transition.to, FlowState::Validated);\n\n    // 6. Continue through Validated \u2192 Priced \u2192 Finalized \u2192 Sent\n    // ... assert each transition succeeds\n\n    // 7. Verify audit trail\n    // ... assert all expected audit events are recorded\n}\n```\n\n## What This Test Catches\n\n- Type mismatches between components (engine output \u2192 repository input)\n- Missing data (product not in catalog, price book entry missing)\n- Initialization order bugs (using engine before data is loaded)\n- Transaction boundary issues (quote saved but lines not committed)\n\n## Dependencies\n\nDepends on bd-sw-1 (ServiceContainer) and at minimum the existing deterministic engines.", "labels": ["server", "integration", "testing"], "parent": "bd-sw"}
